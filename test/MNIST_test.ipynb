{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验计划\n",
    "\n",
    "模型架构mlp+softmax多分类\n",
    "\n",
    "1.实现pytorch版,并且稍微调参\n",
    "\n",
    "2.复刻myTorch版\n",
    "\n",
    "3.基于myTorch做消融实验(优化器，初始化策略)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2024-11-07 10:18:00 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 用于记录每个单元格的运行时间\n",
    "\n",
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nju22\\Desktop\\myTorch\n",
      "time: 0 ns (started: 2024-11-07 10:18:01 +08:00)\n"
     ]
    }
   ],
   "source": [
    "#把项目目录添加至环境变量\n",
    "import os\n",
    "import sys\n",
    "# 获取当前工作目录\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# 获取上级目录\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "print(parent_dir)\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.44 s (started: 2024-11-07 10:18:04 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 基于pytorch导入数据\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "import MyTorch.Dataloader\n",
    "data_dir = \"../../dataset\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:torch.Size([60000, 28, 28])\n",
      "mean:33.31842041015625\n",
      "train_data: 54000\n",
      "val_data: 6000\n",
      "device:cpu\n",
      "time: 3.59 s (started: 2024-11-06 10:00:00 +08:00)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 转换为Tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)),  # 归一化，均值为0.5，标准差为0.5\n",
    "])\n",
    "# MNIST dataset\n",
    "train_data_full = datasets.MNIST(data_dir, train=True, download=True, transform=data_transforms)\n",
    "test_data = datasets.MNIST(data_dir, train=False, download=True, transform=data_transforms)\n",
    "\n",
    "print(f\"shape:{train_data_full.data.shape}\")\n",
    "print(f\"mean:{train_data_full.data.float().mean()}\")#pytorch dataset的transform只会在取数据进入model时调用，故此时print仍然是原始数据\n",
    "\n",
    "val_size = int(0.1 * len(train_data_full))\n",
    "train_data, val_data = random_split(train_data_full, [len(train_data_full) - val_size, val_size])\n",
    "print(\"train_data:\", len(train_data))\n",
    "print(\"val_data:\", len(val_data))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device:{device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 338 μs (started: 2024-11-04 15:43:15 +08:00)\n"
     ]
    }
   ],
   "source": [
    "#定义固定参数\n",
    "input_size = 28 * 28\n",
    "num_classes = 10\n",
    "#定义超参\n",
    "batch_size = 64\n",
    "hidden_size = 128\n",
    "lr=0.1\n",
    "momentum = 0.9\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.92 ms (started: 2024-11-04 15:43:15 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 构建model\n",
    "from torch import nn\n",
    "model=torch.nn.Sequential(nn.Linear(input_size, hidden_size),nn.ReLU(),nn.Linear(hidden_size, num_classes),nn.Softmax(dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 957 μs (started: 2024-11-04 15:43:15 +08:00)\n"
     ]
    }
   ],
   "source": [
    "def val_eval(model,val_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.view(-1, 28 * 28)\n",
    "            images,labels=images.to(device),labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += len(labels)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc=correct/total\n",
    "    print(f\"acc:{acc}\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 687 μs (started: 2024-11-04 15:43:15 +08:00)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import optuna\n",
    "except ModuleNotFoundError:\n",
    "    !pip install optuna\n",
    "    import optuna\n",
    "\n",
    "try:\n",
    "    import tqdm\n",
    "except ModuleNotFoundError:\n",
    "    !pip install tqdm\n",
    "    import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.36 ms (started: 2024-11-04 15:43:15 +08:00)\n"
     ]
    }
   ],
   "source": [
    "def obj(trails):\n",
    "    kwargs = {\n",
    "        \"hidden_size\": trails.suggest_int(\"hidden_size\", 32, 128),\n",
    "        \"batch_size\": trails.suggest_int(\"batch_size\", 64, 64),\n",
    "        \"lr\": trails.suggest_float(\"lr\", 0.001, 0.1),\n",
    "        \"momentum\": trails.suggest_float(\"momentum\", 0.5, 0.9),\n",
    "        epochs: trails.suggest_int(\"epochs\", 2,10 ),\n",
    "    }\n",
    "    model=torch.nn.Sequential(nn.Linear(input_size, kwargs[\"hidden_size\"]),nn.ReLU(),nn.Linear(kwargs[\"hidden_size\"], num_classes),nn.Softmax(dim=1)).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=kwargs[\"lr\"],weight_decay=0.01,momentum=kwargs[\"momentum\"])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_loader =torch.utils.data.DataLoader(train_data, batch_size=kwargs[\"batch_size\"], shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=kwargs[\"batch_size\"], shuffle=False)\n",
    "    for epoch in range(kwargs[epochs]):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images=images.view(-1,28*28)\n",
    "            images,labels=images.to(device),labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 256 == 0:\n",
    "                print('Epcho [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch, kwargs[epochs], i + 1, len(train_loader), loss.item()))\n",
    "    return val_eval(model,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:43:15,384] A new study created in memory with name: no-name-6df1797f-f235-44b5-b9eb-3ed3af85f4c4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epcho [0/5], Step [256/844], Loss: 1.8234\n",
      "Epcho [0/5], Step [512/844], Loss: 1.6936\n",
      "Epcho [0/5], Step [768/844], Loss: 1.7346\n",
      "Epcho [1/5], Step [256/844], Loss: 1.6231\n",
      "Epcho [1/5], Step [512/844], Loss: 1.5874\n",
      "Epcho [1/5], Step [768/844], Loss: 1.6841\n",
      "Epcho [2/5], Step [256/844], Loss: 1.6381\n",
      "Epcho [2/5], Step [512/844], Loss: 1.6210\n",
      "Epcho [2/5], Step [768/844], Loss: 1.5802\n",
      "Epcho [3/5], Step [256/844], Loss: 1.5984\n",
      "Epcho [3/5], Step [512/844], Loss: 1.6160\n",
      "Epcho [3/5], Step [768/844], Loss: 1.6319\n",
      "Epcho [4/5], Step [256/844], Loss: 1.5426\n",
      "Epcho [4/5], Step [512/844], Loss: 1.5979\n",
      "Epcho [4/5], Step [768/844], Loss: 1.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:43:50,001] Trial 0 finished with value: 0.905 and parameters: {'hidden_size': 84, 'batch_size': 64, 'lr': 0.048158069573203, 'momentum': 0.5800218672518666, 'epochs': 5}. Best is trial 0 with value: 0.905.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.905\n",
      "Epcho [0/9], Step [256/844], Loss: 1.8083\n",
      "Epcho [0/9], Step [512/844], Loss: 1.7627\n",
      "Epcho [0/9], Step [768/844], Loss: 1.6454\n",
      "Epcho [1/9], Step [256/844], Loss: 1.8191\n",
      "Epcho [1/9], Step [512/844], Loss: 1.7014\n",
      "Epcho [1/9], Step [768/844], Loss: 1.6850\n",
      "Epcho [2/9], Step [256/844], Loss: 1.5953\n",
      "Epcho [2/9], Step [512/844], Loss: 1.6513\n",
      "Epcho [2/9], Step [768/844], Loss: 1.6064\n",
      "Epcho [3/9], Step [256/844], Loss: 1.6671\n",
      "Epcho [3/9], Step [512/844], Loss: 1.5993\n",
      "Epcho [3/9], Step [768/844], Loss: 1.6409\n",
      "Epcho [4/9], Step [256/844], Loss: 1.6378\n",
      "Epcho [4/9], Step [512/844], Loss: 1.5856\n",
      "Epcho [4/9], Step [768/844], Loss: 1.5886\n",
      "Epcho [5/9], Step [256/844], Loss: 1.5755\n",
      "Epcho [5/9], Step [512/844], Loss: 1.6198\n",
      "Epcho [5/9], Step [768/844], Loss: 1.6121\n",
      "Epcho [6/9], Step [256/844], Loss: 1.5892\n",
      "Epcho [6/9], Step [512/844], Loss: 1.6596\n",
      "Epcho [6/9], Step [768/844], Loss: 1.5978\n",
      "Epcho [7/9], Step [256/844], Loss: 1.6144\n",
      "Epcho [7/9], Step [512/844], Loss: 1.6433\n",
      "Epcho [7/9], Step [768/844], Loss: 1.6277\n",
      "Epcho [8/9], Step [256/844], Loss: 1.6680\n",
      "Epcho [8/9], Step [512/844], Loss: 1.5925\n",
      "Epcho [8/9], Step [768/844], Loss: 1.5885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:44:51,495] Trial 1 finished with value: 0.907 and parameters: {'hidden_size': 117, 'batch_size': 64, 'lr': 0.026192165546679236, 'momentum': 0.622243329796311, 'epochs': 9}. Best is trial 1 with value: 0.907.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.907\n",
      "Epcho [0/6], Step [256/844], Loss: 1.7430\n",
      "Epcho [0/6], Step [512/844], Loss: 1.6521\n",
      "Epcho [0/6], Step [768/844], Loss: 1.6996\n",
      "Epcho [1/6], Step [256/844], Loss: 1.6377\n",
      "Epcho [1/6], Step [512/844], Loss: 1.6865\n",
      "Epcho [1/6], Step [768/844], Loss: 1.6739\n",
      "Epcho [2/6], Step [256/844], Loss: 1.6201\n",
      "Epcho [2/6], Step [512/844], Loss: 1.6402\n",
      "Epcho [2/6], Step [768/844], Loss: 1.6341\n",
      "Epcho [3/6], Step [256/844], Loss: 1.6237\n",
      "Epcho [3/6], Step [512/844], Loss: 1.5964\n",
      "Epcho [3/6], Step [768/844], Loss: 1.6364\n",
      "Epcho [4/6], Step [256/844], Loss: 1.5518\n",
      "Epcho [4/6], Step [512/844], Loss: 1.5611\n",
      "Epcho [4/6], Step [768/844], Loss: 1.5656\n",
      "Epcho [5/6], Step [256/844], Loss: 1.6669\n",
      "Epcho [5/6], Step [512/844], Loss: 1.6378\n",
      "Epcho [5/6], Step [768/844], Loss: 1.6819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:45:31,958] Trial 2 finished with value: 0.9071666666666667 and parameters: {'hidden_size': 112, 'batch_size': 64, 'lr': 0.08386399032153453, 'momentum': 0.5947152101611084, 'epochs': 6}. Best is trial 2 with value: 0.9071666666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.9071666666666667\n",
      "Epcho [0/7], Step [256/844], Loss: 1.8138\n",
      "Epcho [0/7], Step [512/844], Loss: 1.6473\n",
      "Epcho [0/7], Step [768/844], Loss: 1.6242\n",
      "Epcho [1/7], Step [256/844], Loss: 1.6165\n",
      "Epcho [1/7], Step [512/844], Loss: 1.5554\n",
      "Epcho [1/7], Step [768/844], Loss: 1.6466\n",
      "Epcho [2/7], Step [256/844], Loss: 1.6055\n",
      "Epcho [2/7], Step [512/844], Loss: 1.5978\n",
      "Epcho [2/7], Step [768/844], Loss: 1.6162\n",
      "Epcho [3/7], Step [256/844], Loss: 1.5821\n",
      "Epcho [3/7], Step [512/844], Loss: 1.5994\n",
      "Epcho [3/7], Step [768/844], Loss: 1.6678\n",
      "Epcho [4/7], Step [256/844], Loss: 1.6048\n",
      "Epcho [4/7], Step [512/844], Loss: 1.5880\n",
      "Epcho [4/7], Step [768/844], Loss: 1.6159\n",
      "Epcho [5/7], Step [256/844], Loss: 1.6026\n",
      "Epcho [5/7], Step [512/844], Loss: 1.5967\n",
      "Epcho [5/7], Step [768/844], Loss: 1.5537\n",
      "Epcho [6/7], Step [256/844], Loss: 1.5460\n",
      "Epcho [6/7], Step [512/844], Loss: 1.5703\n",
      "Epcho [6/7], Step [768/844], Loss: 1.5782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:46:19,115] Trial 3 finished with value: 0.9118333333333334 and parameters: {'hidden_size': 114, 'batch_size': 64, 'lr': 0.03465737987331803, 'momentum': 0.8057131288832868, 'epochs': 7}. Best is trial 3 with value: 0.9118333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.9118333333333334\n",
      "Epcho [0/3], Step [256/844], Loss: 1.6271\n",
      "Epcho [0/3], Step [512/844], Loss: 1.6747\n",
      "Epcho [0/3], Step [768/844], Loss: 1.6305\n",
      "Epcho [1/3], Step [256/844], Loss: 1.5538\n",
      "Epcho [1/3], Step [512/844], Loss: 1.6638\n",
      "Epcho [1/3], Step [768/844], Loss: 1.5670\n",
      "Epcho [2/3], Step [256/844], Loss: 1.6190\n",
      "Epcho [2/3], Step [512/844], Loss: 1.5728\n",
      "Epcho [2/3], Step [768/844], Loss: 1.5590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:46:39,636] Trial 4 finished with value: 0.8946666666666667 and parameters: {'hidden_size': 86, 'batch_size': 64, 'lr': 0.08125572847743215, 'momentum': 0.6826258064144499, 'epochs': 3}. Best is trial 3 with value: 0.9118333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.8946666666666667\n",
      "Epcho [0/7], Step [256/844], Loss: 1.7782\n",
      "Epcho [0/7], Step [512/844], Loss: 1.7338\n",
      "Epcho [0/7], Step [768/844], Loss: 1.8554\n",
      "Epcho [1/7], Step [256/844], Loss: 1.7009\n",
      "Epcho [1/7], Step [512/844], Loss: 1.6037\n",
      "Epcho [1/7], Step [768/844], Loss: 1.5977\n",
      "Epcho [2/7], Step [256/844], Loss: 1.6872\n",
      "Epcho [2/7], Step [512/844], Loss: 1.6144\n",
      "Epcho [2/7], Step [768/844], Loss: 1.5968\n",
      "Epcho [3/7], Step [256/844], Loss: 1.6242\n",
      "Epcho [3/7], Step [512/844], Loss: 1.6043\n",
      "Epcho [3/7], Step [768/844], Loss: 1.5923\n",
      "Epcho [4/7], Step [256/844], Loss: 1.6158\n",
      "Epcho [4/7], Step [512/844], Loss: 1.6641\n",
      "Epcho [4/7], Step [768/844], Loss: 1.6200\n",
      "Epcho [5/7], Step [256/844], Loss: 1.6086\n",
      "Epcho [5/7], Step [512/844], Loss: 1.5659\n",
      "Epcho [5/7], Step [768/844], Loss: 1.6013\n",
      "Epcho [6/7], Step [256/844], Loss: 1.6493\n",
      "Epcho [6/7], Step [512/844], Loss: 1.6273\n",
      "Epcho [6/7], Step [768/844], Loss: 1.6182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:47:26,797] Trial 5 finished with value: 0.9053333333333333 and parameters: {'hidden_size': 89, 'batch_size': 64, 'lr': 0.028592217180912864, 'momentum': 0.7727646122572475, 'epochs': 7}. Best is trial 3 with value: 0.9118333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.9053333333333333\n",
      "Epcho [0/2], Step [256/844], Loss: 1.6703\n",
      "Epcho [0/2], Step [512/844], Loss: 1.7070\n",
      "Epcho [0/2], Step [768/844], Loss: 1.6383\n",
      "Epcho [1/2], Step [256/844], Loss: 1.6832\n",
      "Epcho [1/2], Step [512/844], Loss: 1.6445\n",
      "Epcho [1/2], Step [768/844], Loss: 1.5914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:47:40,735] Trial 6 finished with value: 0.8903333333333333 and parameters: {'hidden_size': 115, 'batch_size': 64, 'lr': 0.045840187004281344, 'momentum': 0.6193892476972579, 'epochs': 2}. Best is trial 3 with value: 0.9118333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.8903333333333333\n",
      "Epcho [0/9], Step [256/844], Loss: 2.0659\n",
      "Epcho [0/9], Step [512/844], Loss: 1.9434\n",
      "Epcho [0/9], Step [768/844], Loss: 1.8979\n",
      "Epcho [1/9], Step [256/844], Loss: 1.8272\n",
      "Epcho [1/9], Step [512/844], Loss: 1.6898\n",
      "Epcho [1/9], Step [768/844], Loss: 1.6775\n",
      "Epcho [2/9], Step [256/844], Loss: 1.6033\n",
      "Epcho [2/9], Step [512/844], Loss: 1.6753\n",
      "Epcho [2/9], Step [768/844], Loss: 1.6305\n",
      "Epcho [3/9], Step [256/844], Loss: 1.6494\n",
      "Epcho [3/9], Step [512/844], Loss: 1.6158\n",
      "Epcho [3/9], Step [768/844], Loss: 1.6142\n",
      "Epcho [4/9], Step [256/844], Loss: 1.6403\n",
      "Epcho [4/9], Step [512/844], Loss: 1.6061\n",
      "Epcho [4/9], Step [768/844], Loss: 1.6253\n",
      "Epcho [5/9], Step [256/844], Loss: 1.5953\n",
      "Epcho [5/9], Step [512/844], Loss: 1.5573\n",
      "Epcho [5/9], Step [768/844], Loss: 1.6189\n",
      "Epcho [6/9], Step [256/844], Loss: 1.5964\n",
      "Epcho [6/9], Step [512/844], Loss: 1.5744\n",
      "Epcho [6/9], Step [768/844], Loss: 1.5972\n",
      "Epcho [7/9], Step [256/844], Loss: 1.6726\n",
      "Epcho [7/9], Step [512/844], Loss: 1.6114\n",
      "Epcho [7/9], Step [768/844], Loss: 1.5758\n",
      "Epcho [8/9], Step [256/844], Loss: 1.6050\n",
      "Epcho [8/9], Step [512/844], Loss: 1.5932\n",
      "Epcho [8/9], Step [768/844], Loss: 1.5937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:48:40,855] Trial 7 finished with value: 0.9021666666666667 and parameters: {'hidden_size': 114, 'batch_size': 64, 'lr': 0.013845741240680661, 'momentum': 0.5308481853025109, 'epochs': 9}. Best is trial 3 with value: 0.9118333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.9021666666666667\n",
      "Epcho [0/2], Step [256/844], Loss: 1.7106\n",
      "Epcho [0/2], Step [512/844], Loss: 1.8768\n",
      "Epcho [0/2], Step [768/844], Loss: 1.6719\n",
      "Epcho [1/2], Step [256/844], Loss: 1.6384\n",
      "Epcho [1/2], Step [512/844], Loss: 1.5942\n",
      "Epcho [1/2], Step [768/844], Loss: 1.5762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:48:54,869] Trial 8 finished with value: 0.8975 and parameters: {'hidden_size': 63, 'batch_size': 64, 'lr': 0.02604661414070332, 'momentum': 0.8097798962822866, 'epochs': 2}. Best is trial 3 with value: 0.9118333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.8975\n",
      "Epcho [0/7], Step [256/844], Loss: 1.7798\n",
      "Epcho [0/7], Step [512/844], Loss: 1.6369\n",
      "Epcho [0/7], Step [768/844], Loss: 1.5939\n",
      "Epcho [1/7], Step [256/844], Loss: 1.6848\n",
      "Epcho [1/7], Step [512/844], Loss: 1.6126\n",
      "Epcho [1/7], Step [768/844], Loss: 1.6369\n",
      "Epcho [2/7], Step [256/844], Loss: 1.6470\n",
      "Epcho [2/7], Step [512/844], Loss: 1.6486\n",
      "Epcho [2/7], Step [768/844], Loss: 1.5892\n",
      "Epcho [3/7], Step [256/844], Loss: 1.5693\n",
      "Epcho [3/7], Step [512/844], Loss: 1.6175\n",
      "Epcho [3/7], Step [768/844], Loss: 1.5964\n",
      "Epcho [4/7], Step [256/844], Loss: 1.5593\n",
      "Epcho [4/7], Step [512/844], Loss: 1.6193\n",
      "Epcho [4/7], Step [768/844], Loss: 1.5616\n",
      "Epcho [5/7], Step [256/844], Loss: 1.5928\n",
      "Epcho [5/7], Step [512/844], Loss: 1.6234\n",
      "Epcho [5/7], Step [768/844], Loss: 1.6238\n",
      "Epcho [6/7], Step [256/844], Loss: 1.5769\n",
      "Epcho [6/7], Step [512/844], Loss: 1.6161\n",
      "Epcho [6/7], Step [768/844], Loss: 1.5871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:49:42,254] Trial 9 finished with value: 0.9058333333333334 and parameters: {'hidden_size': 49, 'batch_size': 64, 'lr': 0.09058703178482988, 'momentum': 0.631339603916554, 'epochs': 7}. Best is trial 3 with value: 0.9118333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.9058333333333334\n",
      "time: 6min 26s (started: 2024-11-04 15:43:15 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class TqdmCallback(object):\n",
    "    def __init__(self, n_trials):\n",
    "        self.n_trials = n_trials\n",
    "        self.pbar = tqdm(total=n_trials)\n",
    "\n",
    "    def __call__(self, study, trial):\n",
    "        self.pbar.update(1)\n",
    "\n",
    "n_trials = 10\n",
    "tqdm_callback = TqdmCallback(n_trials)\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(obj, n_trials=n_trials, callbacks=[tqdm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2024-11-07 10:18:10 +08:00)\n"
     ]
    }
   ],
   "source": [
    "#固定参数\n",
    "input_size = 28 * 28\n",
    "num_classes = 10\n",
    "batch_size = 64\n",
    "#固定掉超参数\n",
    "lr= 0.09058703178482988\n",
    "hidden_size=50\n",
    "momentum=0.631339603916554\n",
    "epochs=10 #几个不同epoch差别不太大，多训两轮是不会导致性能明显下降的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.7037\n",
      "Epoch [2/10], Loss: 1.6115\n",
      "Epoch [3/10], Loss: 1.5419\n",
      "Epoch [4/10], Loss: 1.5849\n",
      "Epoch [5/10], Loss: 1.5561\n",
      "Epoch [6/10], Loss: 1.7715\n",
      "Epoch [7/10], Loss: 1.6179\n",
      "Epoch [8/10], Loss: 1.5141\n",
      "Epoch [9/10], Loss: 1.6338\n",
      "Epoch [10/10], Loss: 1.6201\n",
      "time: 1min 28s (started: 2024-11-06 10:00:39 +08:00)\n"
     ]
    }
   ],
   "source": [
    "#使用完整训练集训练并测试pytorch版\n",
    "import torch.nn as nn\n",
    "train_loader_full = torch.utils.data.DataLoader(train_data_full, batch_size=batch_size, shuffle=True)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, num_classes),\n",
    "    nn.Softmax(dim=1)\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader_full:\n",
    "        images = images.view(-1, 28 * 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用测试集测试\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "acc=val_eval(model,test_loader)\n",
    "print(f\"final acc:{acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31 ms (started: 2024-11-07 10:18:17 +08:00)\n"
     ]
    }
   ],
   "source": [
    "#基于myTorch进行构建\n",
    "#基于myTorch的dataset导入数据\n",
    "import MyTorch.Dataloader\n",
    "import numpy as np\n",
    "from torchvision import datasets,transforms\n",
    "from PIL  import Image\n",
    "import importlib\n",
    "importlib.reload(MyTorch.Dataloader)\n",
    "importlib.reload(MyTorch.my_nn)\n",
    "importlib.reload(MyTorch.loss_func)\n",
    "#把dataset转为numpy的形式\n",
    "class trans2normalizedNumpy(object):\n",
    "    def __call__(self, img):\n",
    "        np_img=np.array(img)\n",
    "        np_img_flat=np_img.flatten()\n",
    "        #归一化到\n",
    "        np_img_flat = np_img_flat.astype(float)\n",
    "        np_img_flat-=0.5\n",
    "        np_img_flat/=0.5\n",
    "        return np_img_flat\n",
    "myTensor_transforms = trans2normalizedNumpy()\n",
    "train_data_full = datasets.MNIST(data_dir, train=True, download=True, transform=myTensor_transforms)\n",
    "test_data = datasets.MNIST(data_dir, train=False, download=True, transform=myTensor_transforms)\n",
    "\n",
    "train_dataloader = MyTorch.Dataloader.DataLoader(train_data_full, batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = MyTorch.Dataloader.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nju22\\Desktop\\myTorch\\MyTorch\\myTensor.py:549: RuntimeWarning: divide by zero encountered in log\n",
      "  result=np.log(args[0].data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyTensor([[-3.48795681e+02 -1.79525177e+02 -7.78292622e+01 -4.05397627e-09\n",
      "  -2.50102033e+02 -1.93235676e+01 -3.49825286e+02            -inf\n",
      "  -3.96359537e+02 -3.05428330e+02]\n",
      " [-4.61349376e+02 -5.90817401e+02 -1.21456257e+02  0.00000000e+00\n",
      "  -6.31758142e+02 -2.23538842e+02            -inf            -inf\n",
      "  -2.78667724e+02 -4.71758848e+02]\n",
      " [-5.97667673e+02 -5.75414906e+02 -2.98797943e+02  0.00000000e+00\n",
      "  -5.26756164e+02 -2.95057564e+02 -4.74352699e+02            -inf\n",
      "  -4.79241900e+02            -inf]\n",
      " [           -inf -6.94242648e+02 -4.11700193e+02  0.00000000e+00\n",
      "  -5.67744692e+02 -1.91308172e+02            -inf            -inf\n",
      "  -4.88063683e+02 -6.81097880e+02]\n",
      " [-1.63766556e+02 -3.60970778e+02 -1.94899536e+02 -2.35424516e+01\n",
      "  -3.95962889e+02 -5.96545036e-11 -5.34892594e+02 -3.33617508e+02\n",
      "  -3.63962785e+02 -7.01565378e+02]\n",
      " [-3.98440020e+02 -7.33696726e+01 -1.50184502e+01 -3.00310141e-07\n",
      "  -4.44537098e+02 -4.29231617e+01 -4.29582689e+02            -inf\n",
      "  -3.25829255e+02 -4.92001943e+02]\n",
      " [-7.37999125e+02 -6.19155063e+02 -4.76528301e+02  0.00000000e+00\n",
      "  -7.41732022e+02 -2.44053210e+02            -inf            -inf\n",
      "  -3.24579125e+02            -inf]\n",
      " [-2.20192054e+02 -6.98195084e+02 -3.47172631e+02 -2.37663840e+02\n",
      "  -5.40074399e+02  0.00000000e+00            -inf -4.27968883e+02\n",
      "  -5.12428646e+02 -6.24972456e+02]\n",
      " [           -inf  0.00000000e+00 -2.80960649e+02 -5.27910831e+01\n",
      "  -3.69365481e+02 -4.28706133e+01 -6.60657772e+02            -inf\n",
      "  -5.21477513e+02            -inf]\n",
      " [-3.70835943e+02 -5.35305009e+02 -3.83540776e+02  0.00000000e+00\n",
      "  -4.99983595e+02 -1.84429705e+02            -inf -6.46429128e+02\n",
      "  -6.77391486e+02 -6.52304004e+02]\n",
      " [-5.63801396e+02 -6.45099392e+02 -3.85596476e+02  0.00000000e+00\n",
      "  -3.63222126e+02 -2.42686881e+02            -inf -6.08856435e+02\n",
      "  -4.24717750e+02            -inf]\n",
      " [-5.05905209e+02 -2.76128885e+02 -9.01842900e+01  0.00000000e+00\n",
      "  -3.66329107e+02 -1.46389333e+02 -4.10835437e+02 -5.97356062e+02\n",
      "  -6.90109661e+02 -6.88727089e+02]\n",
      " [-5.95299391e+02 -4.64541993e+02  0.00000000e+00 -1.59338232e+02\n",
      "  -5.17868218e+02 -2.00414567e+02 -6.36302768e+02            -inf\n",
      "  -5.17623944e+02 -6.45802261e+02]\n",
      " [-6.33819198e+02 -3.70427391e+02 -9.72086446e+01 -4.48377019e-03\n",
      "  -1.51281981e+01 -5.40959223e+00 -2.78826130e+02            -inf\n",
      "  -6.62200781e+02 -6.31338905e+02]\n",
      " [           -inf -5.53283622e+02 -6.00110759e+02  0.00000000e+00\n",
      "             -inf -3.82103994e+02            -inf            -inf\n",
      "             -inf            -inf]\n",
      " [-2.44272352e+02 -1.01554481e+01 -1.21811987e+01 -4.39906676e-05\n",
      "  -3.94020015e+02 -4.04014698e+01 -3.76570937e+02 -6.55069260e+02\n",
      "  -3.30656799e+02 -5.61811918e+02]\n",
      " [-7.19994173e+02 -6.10565828e+02 -6.10780432e+02  0.00000000e+00\n",
      "  -6.49828749e+02 -3.36804918e+02 -6.34581668e+02 -7.40205965e+02\n",
      "  -6.69876604e+02            -inf]\n",
      " [-3.10258711e+02 -5.20112710e+02 -9.75794203e+01 -9.12711274e+00\n",
      "  -1.08684823e-04 -1.29090945e+02 -4.25482285e+02 -6.14527855e+02\n",
      "  -3.37454369e+02 -4.26949306e+02]\n",
      " [-5.54701765e+02 -4.26423171e+02 -3.34201441e+02  0.00000000e+00\n",
      "  -5.89868526e+02 -1.50374055e+02 -4.52205393e+02 -5.21803932e+02\n",
      "  -4.29680030e+02            -inf]\n",
      " [           -inf -3.23748140e+02 -3.84746014e+02 -1.47733590e+02\n",
      "  -3.07930291e+02  0.00000000e+00 -4.47347411e+02            -inf\n",
      "  -6.04607459e+02            -inf]\n",
      " [-6.83076848e+02 -5.36543067e+02 -3.13707652e+02  0.00000000e+00\n",
      "  -5.11569640e+02 -3.85813388e+02 -6.50124703e+02            -inf\n",
      "             -inf            -inf]\n",
      " [-3.63019673e+02 -2.28571219e+02 -3.70158593e-03 -1.37857960e+02\n",
      "  -5.60084414e+00 -8.86143298e+01 -5.14897292e+02            -inf\n",
      "  -2.98991919e+02 -5.07177708e+02]\n",
      " [-6.78431574e+02 -5.94001355e+02 -5.19166176e+02 -3.04788407e+02\n",
      "             -inf  0.00000000e+00            -inf            -inf\n",
      "  -6.10653566e+02 -5.32592354e+02]\n",
      " [-4.14650268e+02 -4.84253335e-02 -3.05184714e+00 -1.47756052e+02\n",
      "  -3.00456517e+02 -1.36456409e+02 -3.40219038e+02 -7.10397184e+02\n",
      "  -2.89499491e+02 -6.73676730e+02]\n",
      " [-2.67306115e+02  0.00000000e+00 -1.73532953e+02 -2.23373171e+02\n",
      "  -5.59765143e+02 -4.65821135e+01 -4.29241237e+02 -3.66967170e+02\n",
      "  -4.59640916e+02 -5.75716573e+02]\n",
      " [           -inf -4.12010707e+02 -3.90814366e+02  0.00000000e+00\n",
      "             -inf -3.71043192e+02 -6.32530534e+02            -inf\n",
      "             -inf            -inf]\n",
      " [           -inf            -inf -4.72875713e+02  0.00000000e+00\n",
      "             -inf -4.13035630e+02            -inf            -inf\n",
      "             -inf            -inf]\n",
      " [           -inf -5.76706273e+02 -4.54003872e+02  0.00000000e+00\n",
      "             -inf -3.73435268e+02            -inf            -inf\n",
      "             -inf            -inf]\n",
      " [-3.73503891e+02 -4.87490544e+02 -1.23953969e+02 -5.31245179e+01\n",
      "  -5.93049390e+02  0.00000000e+00            -inf            -inf\n",
      "  -5.74784579e+01 -6.78785266e+02]\n",
      " [-3.66960417e+02 -4.16933284e+02 -3.19368522e+02  0.00000000e+00\n",
      "  -2.78224760e+02 -1.54130549e+02 -6.20011912e+02 -7.42648312e+02\n",
      "  -3.11194037e+02            -inf]\n",
      " [-5.47551691e+02 -7.12132677e+02 -6.20172632e+02  0.00000000e+00\n",
      "  -4.86313269e+02 -4.27731866e+02            -inf            -inf\n",
      "  -4.41894283e+02 -6.99292252e+02]\n",
      " [-7.37390817e+02            -inf -2.96987680e+02  0.00000000e+00\n",
      "  -6.06572172e+02 -3.88691698e+02            -inf            -inf\n",
      "  -6.14041034e+02            -inf]\n",
      " [-2.66941746e+02 -6.85285539e+02 -1.65742205e+02 -2.16244552e+02\n",
      "  -4.95067265e+02  0.00000000e+00            -inf -3.78270632e+02\n",
      "  -2.57407389e+02 -6.96061149e+02]\n",
      " [-3.59293064e+02 -2.00095066e+02 -1.55346637e+02 -1.64548073e+02\n",
      "  -2.78300512e+02  0.00000000e+00 -6.51731501e+02 -4.93268486e+02\n",
      "  -2.85962376e+02 -5.42099620e+02]\n",
      " [-4.23945633e+02 -2.84957709e+02 -1.42597382e+02 -4.16203968e+01\n",
      "  -3.16687960e+02  0.00000000e+00 -6.24555241e+02            -inf\n",
      "             -inf -4.52711962e+02]\n",
      " [           -inf            -inf -4.44627542e+02  0.00000000e+00\n",
      "             -inf -4.96298954e+02            -inf            -inf\n",
      "             -inf            -inf]\n",
      " [-1.97615308e+02 -3.21188217e+01 -2.30629111e+02 -3.66239929e+01\n",
      "  -1.13242749e-14 -2.50425777e+02 -5.66047748e+02 -4.22446242e+02\n",
      "  -1.25339145e+02 -4.67346583e+02]\n",
      " [-2.00043603e+02 -5.47545529e+02 -2.01690912e+02  0.00000000e+00\n",
      "  -4.80272530e+02 -7.84844372e+01 -6.42897931e+02 -5.44146652e+02\n",
      "  -4.08158348e+02 -4.97918149e+02]\n",
      " [-2.87639975e+02 -3.71625580e+01  0.00000000e+00 -5.81750053e+01\n",
      "  -4.27106145e+02 -7.53086588e+01 -1.78145274e+02 -3.25503598e+02\n",
      "  -4.02870788e+02 -3.01298225e+02]\n",
      " [-3.46200165e+02 -3.63054029e+02 -2.77529533e+02  0.00000000e+00\n",
      "  -6.86110580e+02 -2.34542842e+02 -4.74886050e+02 -5.95675905e+02\n",
      "  -5.01979283e+02 -4.90916333e+02]\n",
      " [-4.98239771e+02 -3.64150960e+02 -1.31185214e+02 -1.24482040e-07\n",
      "  -5.24099992e+02 -1.58991045e+01 -5.56960310e+02            -inf\n",
      "  -3.00109050e+02 -5.90690684e+02]\n",
      " [           -inf            -inf -7.14136544e+02  0.00000000e+00\n",
      "             -inf -6.32185574e+02            -inf            -inf\n",
      "             -inf            -inf]\n",
      " [           -inf            -inf -1.82259893e+02  0.00000000e+00\n",
      "  -6.90741073e+02 -1.77007581e+02            -inf            -inf\n",
      "             -inf            -inf]\n",
      " [-1.01228787e+02 -3.92940835e+02 -2.01058774e+02 -2.12555823e+02\n",
      "  -1.93302072e+02  0.00000000e+00 -4.73329849e+02 -7.42648312e+02\n",
      "  -3.77032989e+02 -5.25089734e+02]\n",
      " [-2.93442270e+02 -1.03089996e+02 -1.22893312e+02 -1.87145682e+02\n",
      "             -inf  0.00000000e+00 -3.00061506e+02            -inf\n",
      "  -5.93719569e+02 -5.12575216e+02]\n",
      " [-3.82047887e+02 -4.68343392e+02 -1.59323857e+02  0.00000000e+00\n",
      "  -3.76958286e+02 -2.20753992e+02            -inf            -inf\n",
      "  -1.93897707e+02 -5.38466820e+02]\n",
      " [-1.81418293e+02 -3.37523827e+02 -2.15882823e+02  0.00000000e+00\n",
      "  -5.22756141e+02 -1.78845243e+02 -2.40389996e+02 -4.53459309e+02\n",
      "  -2.48274858e+02 -5.01352818e+02]\n",
      " [-4.45770341e+02 -2.74422431e+02 -2.23653646e+02  0.00000000e+00\n",
      "  -4.14792393e+02 -1.03702443e+02 -5.27038609e+02 -4.03568390e+02\n",
      "  -6.54368670e+02            -inf]\n",
      " [-5.43027627e+02 -4.52969997e+02 -3.55987487e+02  0.00000000e+00\n",
      "             -inf -1.88060468e+02 -7.16807567e+02 -6.18092469e+02\n",
      "  -4.70086362e+02            -inf]\n",
      " [           -inf -5.78048281e+02 -2.38160110e+02  0.00000000e+00\n",
      "  -2.56317172e+02 -1.30034616e+02 -6.20578805e+02            -inf\n",
      "  -3.96362027e+02            -inf]\n",
      " [-4.97553301e+02 -3.64147426e+02 -3.59973258e+02  0.00000000e+00\n",
      "  -6.65944229e+02 -2.62805744e+02 -6.07484813e+02 -7.05226834e+02\n",
      "  -4.80561950e+02            -inf]\n",
      " [-3.59711742e+02 -2.09452379e+02 -3.63940829e+02  0.00000000e+00\n",
      "  -4.07273568e+02 -2.86980561e+02 -3.81052002e+02 -7.02093315e+02\n",
      "  -2.26340985e+02 -7.18423386e+02]\n",
      " [-3.45578903e+02 -3.35526537e+02 -1.87205420e+02 -2.02458511e+01\n",
      "  -4.95606725e+02 -1.61190195e-09 -5.24549694e+02 -7.29309383e+02\n",
      "  -1.53995061e+02 -6.38839356e+02]\n",
      " [-5.66603528e+02 -3.08192431e+01 -3.80813262e+02 -4.13002965e-14\n",
      "  -2.33228649e+02 -5.01779789e+02            -inf -7.31598608e+02\n",
      "  -5.62913260e+02 -7.41801015e+02]\n",
      " [-3.35165871e+02 -4.07494206e+01 -1.21269001e+02 -7.92563629e-09\n",
      "  -1.91405360e+02 -1.86531632e+01 -3.24750642e+02 -2.61666325e+02\n",
      "  -5.66357846e+02 -4.01298928e+02]\n",
      " [-4.34396163e+02 -2.67258869e+02 -2.48467308e+02  0.00000000e+00\n",
      "  -3.63251281e+02 -3.67386727e+02 -6.73994713e+02            -inf\n",
      "  -3.49946699e+02            -inf]\n",
      " [-6.54248990e+02 -7.23749459e+02 -4.22379884e+02  0.00000000e+00\n",
      "             -inf -2.79635799e+02            -inf            -inf\n",
      "             -inf            -inf]\n",
      " [-5.28661947e+02 -2.84337500e+02 -1.19290802e-02 -2.53512301e+02\n",
      "  -2.03527194e+02 -4.43473475e+00 -5.09294308e+02 -6.82631966e+02\n",
      "  -6.70823254e+02 -4.65857242e+02]\n",
      " [-5.29130020e+02            -inf -2.78684194e+02  0.00000000e+00\n",
      "  -6.19560222e+02 -2.20936833e+02            -inf            -inf\n",
      "  -6.74770063e+02            -inf]\n",
      " [-7.02618489e+02            -inf -3.91143776e+02  0.00000000e+00\n",
      "  -6.61851518e+02 -1.61439424e+02            -inf -6.42893064e+02\n",
      "             -inf            -inf]\n",
      " [-2.79774951e+02 -4.33804917e+02 -1.78952189e+02 -1.22117328e+01\n",
      "             -inf -4.97179178e-06 -7.22354879e+02            -inf\n",
      "  -1.78909452e+02            -inf]\n",
      " [-5.44006845e+02 -1.59125150e+02  0.00000000e+00 -2.39165783e+02\n",
      "  -1.93614287e+02 -2.03487816e+02 -5.60623885e+02            -inf\n",
      "  -5.07293078e+02 -5.67858615e+02]\n",
      " [-3.37441317e+02 -4.32361639e+02 -3.31126975e+02  0.00000000e+00\n",
      "  -6.46277741e+02 -1.49680807e+02 -4.95187783e+02 -6.06561613e+02\n",
      "  -4.82013599e+02 -6.87800175e+02]\n",
      " [-4.86846822e+02 -3.19508417e+02 -3.78088112e+02 -1.42223479e+02\n",
      "  -5.94139195e+02  0.00000000e+00 -6.87928417e+02            -inf\n",
      "  -5.19308762e+02            -inf]])\n",
      "MyTensor([[6.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [5.]\n",
      " [2.]\n",
      " [0.]\n",
      " [7.]\n",
      " [3.]\n",
      " [9.]\n",
      " [7.]\n",
      " [7.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [8.]\n",
      " [6.]\n",
      " [1.]\n",
      " [4.]\n",
      " [6.]\n",
      " [7.]\n",
      " [5.]\n",
      " [5.]\n",
      " [8.]\n",
      " [3.]\n",
      " [6.]\n",
      " [6.]\n",
      " [2.]\n",
      " [6.]\n",
      " [3.]\n",
      " [5.]\n",
      " [6.]\n",
      " [7.]\n",
      " [3.]\n",
      " [6.]\n",
      " [8.]\n",
      " [9.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [6.]\n",
      " [0.]\n",
      " [3.]\n",
      " [5.]\n",
      " [2.]\n",
      " [1.]\n",
      " [5.]\n",
      " [1.]\n",
      " [4.]\n",
      " [5.]\n",
      " [8.]\n",
      " [6.]\n",
      " [7.]\n",
      " [5.]\n",
      " [6.]\n",
      " [8.]\n",
      " [5.]\n",
      " [8.]\n",
      " [8.]\n",
      " [2.]\n",
      " [7.]\n",
      " [1.]\n",
      " [0.]])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "MyTensor([[-3.48795681e+02 -1.79525177e+02 -7.78292622e+01 -4.05397627e-09\n  -2.50102033e+02 -1.93235676e+01 -3.49825286e+02            -inf\n  -3.96359537e+02 -3.05428330e+02]\n [-4.61349376e+02 -5.90817401e+02 -1.21456257e+02  0.00000000e+00\n  -6.31758142e+02 -2.23538842e+02            -inf            -inf\n  -2.78667724e+02 -4.71758848e+02]\n [-5.97667673e+02 -5.75414906e+02 -2.98797943e+02  0.00000000e+00\n  -5.26756164e+02 -2.95057564e+02 -4.74352699e+02            -inf\n  -4.79241900e+02            -inf]\n [           -inf -6.94242648e+02 -4.11700193e+02  0.00000000e+00\n  -5.67744692e+02 -1.91308172e+02            -inf            -inf\n  -4.88063683e+02 -6.81097880e+02]\n [-1.63766556e+02 -3.60970778e+02 -1.94899536e+02 -2.35424516e+01\n  -3.95962889e+02 -5.96545036e-11 -5.34892594e+02 -3.33617508e+02\n  -3.63962785e+02 -7.01565378e+02]\n [-3.98440020e+02 -7.33696726e+01 -1.50184502e+01 -3.00310141e-07\n  -4.44537098e+02 -4.29231617e+01 -4.29582689e+02            -inf\n  -3.25829255e+02 -4.92001943e+02]\n [-7.37999125e+02 -6.19155063e+02 -4.76528301e+02  0.00000000e+00\n  -7.41732022e+02 -2.44053210e+02            -inf            -inf\n  -3.24579125e+02            -inf]\n [-2.20192054e+02 -6.98195084e+02 -3.47172631e+02 -2.37663840e+02\n  -5.40074399e+02  0.00000000e+00            -inf -4.27968883e+02\n  -5.12428646e+02 -6.24972456e+02]\n [           -inf  0.00000000e+00 -2.80960649e+02 -5.27910831e+01\n  -3.69365481e+02 -4.28706133e+01 -6.60657772e+02            -inf\n  -5.21477513e+02            -inf]\n [-3.70835943e+02 -5.35305009e+02 -3.83540776e+02  0.00000000e+00\n  -4.99983595e+02 -1.84429705e+02            -inf -6.46429128e+02\n  -6.77391486e+02 -6.52304004e+02]\n [-5.63801396e+02 -6.45099392e+02 -3.85596476e+02  0.00000000e+00\n  -3.63222126e+02 -2.42686881e+02            -inf -6.08856435e+02\n  -4.24717750e+02            -inf]\n [-5.05905209e+02 -2.76128885e+02 -9.01842900e+01  0.00000000e+00\n  -3.66329107e+02 -1.46389333e+02 -4.10835437e+02 -5.97356062e+02\n  -6.90109661e+02 -6.88727089e+02]\n [-5.95299391e+02 -4.64541993e+02  0.00000000e+00 -1.59338232e+02\n  -5.17868218e+02 -2.00414567e+02 -6.36302768e+02            -inf\n  -5.17623944e+02 -6.45802261e+02]\n [-6.33819198e+02 -3.70427391e+02 -9.72086446e+01 -4.48377019e-03\n  -1.51281981e+01 -5.40959223e+00 -2.78826130e+02            -inf\n  -6.62200781e+02 -6.31338905e+02]\n [           -inf -5.53283622e+02 -6.00110759e+02  0.00000000e+00\n             -inf -3.82103994e+02            -inf            -inf\n             -inf            -inf]\n [-2.44272352e+02 -1.01554481e+01 -1.21811987e+01 -4.39906676e-05\n  -3.94020015e+02 -4.04014698e+01 -3.76570937e+02 -6.55069260e+02\n  -3.30656799e+02 -5.61811918e+02]\n [-7.19994173e+02 -6.10565828e+02 -6.10780432e+02  0.00000000e+00\n  -6.49828749e+02 -3.36804918e+02 -6.34581668e+02 -7.40205965e+02\n  -6.69876604e+02            -inf]\n [-3.10258711e+02 -5.20112710e+02 -9.75794203e+01 -9.12711274e+00\n  -1.08684823e-04 -1.29090945e+02 -4.25482285e+02 -6.14527855e+02\n  -3.37454369e+02 -4.26949306e+02]\n [-5.54701765e+02 -4.26423171e+02 -3.34201441e+02  0.00000000e+00\n  -5.89868526e+02 -1.50374055e+02 -4.52205393e+02 -5.21803932e+02\n  -4.29680030e+02            -inf]\n [           -inf -3.23748140e+02 -3.84746014e+02 -1.47733590e+02\n  -3.07930291e+02  0.00000000e+00 -4.47347411e+02            -inf\n  -6.04607459e+02            -inf]\n [-6.83076848e+02 -5.36543067e+02 -3.13707652e+02  0.00000000e+00\n  -5.11569640e+02 -3.85813388e+02 -6.50124703e+02            -inf\n             -inf            -inf]\n [-3.63019673e+02 -2.28571219e+02 -3.70158593e-03 -1.37857960e+02\n  -5.60084414e+00 -8.86143298e+01 -5.14897292e+02            -inf\n  -2.98991919e+02 -5.07177708e+02]\n [-6.78431574e+02 -5.94001355e+02 -5.19166176e+02 -3.04788407e+02\n             -inf  0.00000000e+00            -inf            -inf\n  -6.10653566e+02 -5.32592354e+02]\n [-4.14650268e+02 -4.84253335e-02 -3.05184714e+00 -1.47756052e+02\n  -3.00456517e+02 -1.36456409e+02 -3.40219038e+02 -7.10397184e+02\n  -2.89499491e+02 -6.73676730e+02]\n [-2.67306115e+02  0.00000000e+00 -1.73532953e+02 -2.23373171e+02\n  -5.59765143e+02 -4.65821135e+01 -4.29241237e+02 -3.66967170e+02\n  -4.59640916e+02 -5.75716573e+02]\n [           -inf -4.12010707e+02 -3.90814366e+02  0.00000000e+00\n             -inf -3.71043192e+02 -6.32530534e+02            -inf\n             -inf            -inf]\n [           -inf            -inf -4.72875713e+02  0.00000000e+00\n             -inf -4.13035630e+02            -inf            -inf\n             -inf            -inf]\n [           -inf -5.76706273e+02 -4.54003872e+02  0.00000000e+00\n             -inf -3.73435268e+02            -inf            -inf\n             -inf            -inf]\n [-3.73503891e+02 -4.87490544e+02 -1.23953969e+02 -5.31245179e+01\n  -5.93049390e+02  0.00000000e+00            -inf            -inf\n  -5.74784579e+01 -6.78785266e+02]\n [-3.66960417e+02 -4.16933284e+02 -3.19368522e+02  0.00000000e+00\n  -2.78224760e+02 -1.54130549e+02 -6.20011912e+02 -7.42648312e+02\n  -3.11194037e+02            -inf]\n [-5.47551691e+02 -7.12132677e+02 -6.20172632e+02  0.00000000e+00\n  -4.86313269e+02 -4.27731866e+02            -inf            -inf\n  -4.41894283e+02 -6.99292252e+02]\n [-7.37390817e+02            -inf -2.96987680e+02  0.00000000e+00\n  -6.06572172e+02 -3.88691698e+02            -inf            -inf\n  -6.14041034e+02            -inf]\n [-2.66941746e+02 -6.85285539e+02 -1.65742205e+02 -2.16244552e+02\n  -4.95067265e+02  0.00000000e+00            -inf -3.78270632e+02\n  -2.57407389e+02 -6.96061149e+02]\n [-3.59293064e+02 -2.00095066e+02 -1.55346637e+02 -1.64548073e+02\n  -2.78300512e+02  0.00000000e+00 -6.51731501e+02 -4.93268486e+02\n  -2.85962376e+02 -5.42099620e+02]\n [-4.23945633e+02 -2.84957709e+02 -1.42597382e+02 -4.16203968e+01\n  -3.16687960e+02  0.00000000e+00 -6.24555241e+02            -inf\n             -inf -4.52711962e+02]\n [           -inf            -inf -4.44627542e+02  0.00000000e+00\n             -inf -4.96298954e+02            -inf            -inf\n             -inf            -inf]\n [-1.97615308e+02 -3.21188217e+01 -2.30629111e+02 -3.66239929e+01\n  -1.13242749e-14 -2.50425777e+02 -5.66047748e+02 -4.22446242e+02\n  -1.25339145e+02 -4.67346583e+02]\n [-2.00043603e+02 -5.47545529e+02 -2.01690912e+02  0.00000000e+00\n  -4.80272530e+02 -7.84844372e+01 -6.42897931e+02 -5.44146652e+02\n  -4.08158348e+02 -4.97918149e+02]\n [-2.87639975e+02 -3.71625580e+01  0.00000000e+00 -5.81750053e+01\n  -4.27106145e+02 -7.53086588e+01 -1.78145274e+02 -3.25503598e+02\n  -4.02870788e+02 -3.01298225e+02]\n [-3.46200165e+02 -3.63054029e+02 -2.77529533e+02  0.00000000e+00\n  -6.86110580e+02 -2.34542842e+02 -4.74886050e+02 -5.95675905e+02\n  -5.01979283e+02 -4.90916333e+02]\n [-4.98239771e+02 -3.64150960e+02 -1.31185214e+02 -1.24482040e-07\n  -5.24099992e+02 -1.58991045e+01 -5.56960310e+02            -inf\n  -3.00109050e+02 -5.90690684e+02]\n [           -inf            -inf -7.14136544e+02  0.00000000e+00\n             -inf -6.32185574e+02            -inf            -inf\n             -inf            -inf]\n [           -inf            -inf -1.82259893e+02  0.00000000e+00\n  -6.90741073e+02 -1.77007581e+02            -inf            -inf\n             -inf            -inf]\n [-1.01228787e+02 -3.92940835e+02 -2.01058774e+02 -2.12555823e+02\n  -1.93302072e+02  0.00000000e+00 -4.73329849e+02 -7.42648312e+02\n  -3.77032989e+02 -5.25089734e+02]\n [-2.93442270e+02 -1.03089996e+02 -1.22893312e+02 -1.87145682e+02\n             -inf  0.00000000e+00 -3.00061506e+02            -inf\n  -5.93719569e+02 -5.12575216e+02]\n [-3.82047887e+02 -4.68343392e+02 -1.59323857e+02  0.00000000e+00\n  -3.76958286e+02 -2.20753992e+02            -inf            -inf\n  -1.93897707e+02 -5.38466820e+02]\n [-1.81418293e+02 -3.37523827e+02 -2.15882823e+02  0.00000000e+00\n  -5.22756141e+02 -1.78845243e+02 -2.40389996e+02 -4.53459309e+02\n  -2.48274858e+02 -5.01352818e+02]\n [-4.45770341e+02 -2.74422431e+02 -2.23653646e+02  0.00000000e+00\n  -4.14792393e+02 -1.03702443e+02 -5.27038609e+02 -4.03568390e+02\n  -6.54368670e+02            -inf]\n [-5.43027627e+02 -4.52969997e+02 -3.55987487e+02  0.00000000e+00\n             -inf -1.88060468e+02 -7.16807567e+02 -6.18092469e+02\n  -4.70086362e+02            -inf]\n [           -inf -5.78048281e+02 -2.38160110e+02  0.00000000e+00\n  -2.56317172e+02 -1.30034616e+02 -6.20578805e+02            -inf\n  -3.96362027e+02            -inf]\n [-4.97553301e+02 -3.64147426e+02 -3.59973258e+02  0.00000000e+00\n  -6.65944229e+02 -2.62805744e+02 -6.07484813e+02 -7.05226834e+02\n  -4.80561950e+02            -inf]\n [-3.59711742e+02 -2.09452379e+02 -3.63940829e+02  0.00000000e+00\n  -4.07273568e+02 -2.86980561e+02 -3.81052002e+02 -7.02093315e+02\n  -2.26340985e+02 -7.18423386e+02]\n [-3.45578903e+02 -3.35526537e+02 -1.87205420e+02 -2.02458511e+01\n  -4.95606725e+02 -1.61190195e-09 -5.24549694e+02 -7.29309383e+02\n  -1.53995061e+02 -6.38839356e+02]\n [-5.66603528e+02 -3.08192431e+01 -3.80813262e+02 -4.13002965e-14\n  -2.33228649e+02 -5.01779789e+02            -inf -7.31598608e+02\n  -5.62913260e+02 -7.41801015e+02]\n [-3.35165871e+02 -4.07494206e+01 -1.21269001e+02 -7.92563629e-09\n  -1.91405360e+02 -1.86531632e+01 -3.24750642e+02 -2.61666325e+02\n  -5.66357846e+02 -4.01298928e+02]\n [-4.34396163e+02 -2.67258869e+02 -2.48467308e+02  0.00000000e+00\n  -3.63251281e+02 -3.67386727e+02 -6.73994713e+02            -inf\n  -3.49946699e+02            -inf]\n [-6.54248990e+02 -7.23749459e+02 -4.22379884e+02  0.00000000e+00\n             -inf -2.79635799e+02            -inf            -inf\n             -inf            -inf]\n [-5.28661947e+02 -2.84337500e+02 -1.19290802e-02 -2.53512301e+02\n  -2.03527194e+02 -4.43473475e+00 -5.09294308e+02 -6.82631966e+02\n  -6.70823254e+02 -4.65857242e+02]\n [-5.29130020e+02            -inf -2.78684194e+02  0.00000000e+00\n  -6.19560222e+02 -2.20936833e+02            -inf            -inf\n  -6.74770063e+02            -inf]\n [-7.02618489e+02            -inf -3.91143776e+02  0.00000000e+00\n  -6.61851518e+02 -1.61439424e+02            -inf -6.42893064e+02\n             -inf            -inf]\n [-2.79774951e+02 -4.33804917e+02 -1.78952189e+02 -1.22117328e+01\n             -inf -4.97179178e-06 -7.22354879e+02            -inf\n  -1.78909452e+02            -inf]\n [-5.44006845e+02 -1.59125150e+02  0.00000000e+00 -2.39165783e+02\n  -1.93614287e+02 -2.03487816e+02 -5.60623885e+02            -inf\n  -5.07293078e+02 -5.67858615e+02]\n [-3.37441317e+02 -4.32361639e+02 -3.31126975e+02  0.00000000e+00\n  -6.46277741e+02 -1.49680807e+02 -4.95187783e+02 -6.06561613e+02\n  -4.82013599e+02 -6.87800175e+02]\n [-4.86846822e+02 -3.19508417e+02 -3.78088112e+02 -1.42223479e+02\n  -5.94139195e+02  0.00000000e+00 -6.87928417e+02            -inf\n  -5.19308762e+02            -inf]])shape must be the same as MyTensor([[6.]\n [2.]\n [2.]\n [2.]\n [0.]\n [5.]\n [2.]\n [0.]\n [7.]\n [3.]\n [9.]\n [7.]\n [7.]\n [4.]\n [2.]\n [3.]\n [8.]\n [6.]\n [1.]\n [4.]\n [6.]\n [7.]\n [5.]\n [5.]\n [8.]\n [3.]\n [6.]\n [6.]\n [2.]\n [6.]\n [3.]\n [5.]\n [6.]\n [7.]\n [3.]\n [6.]\n [8.]\n [9.]\n [3.]\n [3.]\n [2.]\n [6.]\n [0.]\n [3.]\n [5.]\n [2.]\n [1.]\n [5.]\n [1.]\n [4.]\n [5.]\n [8.]\n [6.]\n [7.]\n [5.]\n [6.]\n [8.]\n [5.]\n [8.]\n [8.]\n [2.]\n [7.]\n [1.]\n [0.]])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m     18\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m---> 19\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nju22\\Desktop\\myTorch\\MyTorch\\loss_func.py:52\u001b[0m, in \u001b[0;36mLossFunc2.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nju22\\Desktop\\myTorch\\MyTorch\\loss_func.py:188\u001b[0m, in \u001b[0;36mNLLLoss.forward\u001b[1;34m(self, y_pred, y_true, reduction)\u001b[0m\n\u001b[0;32m    186\u001b[0m sub\u001b[38;5;241m=\u001b[39mSub()\n\u001b[0;32m    187\u001b[0m log_result\u001b[38;5;241m=\u001b[39mlog\u001b[38;5;241m.\u001b[39mforward(y_pred)\n\u001b[1;32m--> 188\u001b[0m mul_result\u001b[38;5;241m=\u001b[39m\u001b[43mmul\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlog_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m nll_loss\u001b[38;5;241m=\u001b[39msumunary\u001b[38;5;241m.\u001b[39mforward(mul_result)\n\u001b[0;32m    190\u001b[0m zeros\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros_like(nll_loss\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\Users\\nju22\\Desktop\\myTorch\\MyTorch\\myTensor.py:381\u001b[0m, in \u001b[0;36mMul.forward\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    379\u001b[0m myAssert(args\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m()\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMul must have 2 arguments\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args:\n\u001b[1;32m--> 381\u001b[0m     \u001b[43mmyAssert\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43marg\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mshape must be the same as \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m myAssert(\u001b[38;5;28mall\u001b[39m(arg\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice must be the same\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m#算出结果\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nju22\\Desktop\\myTorch\\MyTorch\\utils\\utils.py:19\u001b[0m, in \u001b[0;36mmyAssert\u001b[1;34m(judge, message, *args, **kwargs)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m judge, message\n",
      "\u001b[1;31mAssertionError\u001b[0m: MyTensor([[-3.48795681e+02 -1.79525177e+02 -7.78292622e+01 -4.05397627e-09\n  -2.50102033e+02 -1.93235676e+01 -3.49825286e+02            -inf\n  -3.96359537e+02 -3.05428330e+02]\n [-4.61349376e+02 -5.90817401e+02 -1.21456257e+02  0.00000000e+00\n  -6.31758142e+02 -2.23538842e+02            -inf            -inf\n  -2.78667724e+02 -4.71758848e+02]\n [-5.97667673e+02 -5.75414906e+02 -2.98797943e+02  0.00000000e+00\n  -5.26756164e+02 -2.95057564e+02 -4.74352699e+02            -inf\n  -4.79241900e+02            -inf]\n [           -inf -6.94242648e+02 -4.11700193e+02  0.00000000e+00\n  -5.67744692e+02 -1.91308172e+02            -inf            -inf\n  -4.88063683e+02 -6.81097880e+02]\n [-1.63766556e+02 -3.60970778e+02 -1.94899536e+02 -2.35424516e+01\n  -3.95962889e+02 -5.96545036e-11 -5.34892594e+02 -3.33617508e+02\n  -3.63962785e+02 -7.01565378e+02]\n [-3.98440020e+02 -7.33696726e+01 -1.50184502e+01 -3.00310141e-07\n  -4.44537098e+02 -4.29231617e+01 -4.29582689e+02            -inf\n  -3.25829255e+02 -4.92001943e+02]\n [-7.37999125e+02 -6.19155063e+02 -4.76528301e+02  0.00000000e+00\n  -7.41732022e+02 -2.44053210e+02            -inf            -inf\n  -3.24579125e+02            -inf]\n [-2.20192054e+02 -6.98195084e+02 -3.47172631e+02 -2.37663840e+02\n  -5.40074399e+02  0.00000000e+00            -inf -4.27968883e+02\n  -5.12428646e+02 -6.24972456e+02]\n [           -inf  0.00000000e+00 -2.80960649e+02 -5.27910831e+01\n  -3.69365481e+02 -4.28706133e+01 -6.60657772e+02            -inf\n  -5.21477513e+02            -inf]\n [-3.70835943e+02 -5.35305009e+02 -3.83540776e+02  0.00000000e+00\n  -4.99983595e+02 -1.84429705e+02            -inf -6.46429128e+02\n  -6.77391486e+02 -6.52304004e+02]\n [-5.63801396e+02 -6.45099392e+02 -3.85596476e+02  0.00000000e+00\n  -3.63222126e+02 -2.42686881e+02            -inf -6.08856435e+02\n  -4.24717750e+02            -inf]\n [-5.05905209e+02 -2.76128885e+02 -9.01842900e+01  0.00000000e+00\n  -3.66329107e+02 -1.46389333e+02 -4.10835437e+02 -5.97356062e+02\n  -6.90109661e+02 -6.88727089e+02]\n [-5.95299391e+02 -4.64541993e+02  0.00000000e+00 -1.59338232e+02\n  -5.17868218e+02 -2.00414567e+02 -6.36302768e+02            -inf\n  -5.17623944e+02 -6.45802261e+02]\n [-6.33819198e+02 -3.70427391e+02 -9.72086446e+01 -4.48377019e-03\n  -1.51281981e+01 -5.40959223e+00 -2.78826130e+02            -inf\n  -6.62200781e+02 -6.31338905e+02]\n [           -inf -5.53283622e+02 -6.00110759e+02  0.00000000e+00\n             -inf -3.82103994e+02            -inf            -inf\n             -inf            -inf]\n [-2.44272352e+02 -1.01554481e+01 -1.21811987e+01 -4.39906676e-05\n  -3.94020015e+02 -4.04014698e+01 -3.76570937e+02 -6.55069260e+02\n  -3.30656799e+02 -5.61811918e+02]\n [-7.19994173e+02 -6.10565828e+02 -6.10780432e+02  0.00000000e+00\n  -6.49828749e+02 -3.36804918e+02 -6.34581668e+02 -7.40205965e+02\n  -6.69876604e+02            -inf]\n [-3.10258711e+02 -5.20112710e+02 -9.75794203e+01 -9.12711274e+00\n  -1.08684823e-04 -1.29090945e+02 -4.25482285e+02 -6.14527855e+02\n  -3.37454369e+02 -4.26949306e+02]\n [-5.54701765e+02 -4.26423171e+02 -3.34201441e+02  0.00000000e+00\n  -5.89868526e+02 -1.50374055e+02 -4.52205393e+02 -5.21803932e+02\n  -4.29680030e+02            -inf]\n [           -inf -3.23748140e+02 -3.84746014e+02 -1.47733590e+02\n  -3.07930291e+02  0.00000000e+00 -4.47347411e+02            -inf\n  -6.04607459e+02            -inf]\n [-6.83076848e+02 -5.36543067e+02 -3.13707652e+02  0.00000000e+00\n  -5.11569640e+02 -3.85813388e+02 -6.50124703e+02            -inf\n             -inf            -inf]\n [-3.63019673e+02 -2.28571219e+02 -3.70158593e-03 -1.37857960e+02\n  -5.60084414e+00 -8.86143298e+01 -5.14897292e+02            -inf\n  -2.98991919e+02 -5.07177708e+02]\n [-6.78431574e+02 -5.94001355e+02 -5.19166176e+02 -3.04788407e+02\n             -inf  0.00000000e+00            -inf            -inf\n  -6.10653566e+02 -5.32592354e+02]\n [-4.14650268e+02 -4.84253335e-02 -3.05184714e+00 -1.47756052e+02\n  -3.00456517e+02 -1.36456409e+02 -3.40219038e+02 -7.10397184e+02\n  -2.89499491e+02 -6.73676730e+02]\n [-2.67306115e+02  0.00000000e+00 -1.73532953e+02 -2.23373171e+02\n  -5.59765143e+02 -4.65821135e+01 -4.29241237e+02 -3.66967170e+02\n  -4.59640916e+02 -5.75716573e+02]\n [           -inf -4.12010707e+02 -3.90814366e+02  0.00000000e+00\n             -inf -3.71043192e+02 -6.32530534e+02            -inf\n             -inf            -inf]\n [           -inf            -inf -4.72875713e+02  0.00000000e+00\n             -inf -4.13035630e+02            -inf            -inf\n             -inf            -inf]\n [           -inf -5.76706273e+02 -4.54003872e+02  0.00000000e+00\n             -inf -3.73435268e+02            -inf            -inf\n             -inf            -inf]\n [-3.73503891e+02 -4.87490544e+02 -1.23953969e+02 -5.31245179e+01\n  -5.93049390e+02  0.00000000e+00            -inf            -inf\n  -5.74784579e+01 -6.78785266e+02]\n [-3.66960417e+02 -4.16933284e+02 -3.19368522e+02  0.00000000e+00\n  -2.78224760e+02 -1.54130549e+02 -6.20011912e+02 -7.42648312e+02\n  -3.11194037e+02            -inf]\n [-5.47551691e+02 -7.12132677e+02 -6.20172632e+02  0.00000000e+00\n  -4.86313269e+02 -4.27731866e+02            -inf            -inf\n  -4.41894283e+02 -6.99292252e+02]\n [-7.37390817e+02            -inf -2.96987680e+02  0.00000000e+00\n  -6.06572172e+02 -3.88691698e+02            -inf            -inf\n  -6.14041034e+02            -inf]\n [-2.66941746e+02 -6.85285539e+02 -1.65742205e+02 -2.16244552e+02\n  -4.95067265e+02  0.00000000e+00            -inf -3.78270632e+02\n  -2.57407389e+02 -6.96061149e+02]\n [-3.59293064e+02 -2.00095066e+02 -1.55346637e+02 -1.64548073e+02\n  -2.78300512e+02  0.00000000e+00 -6.51731501e+02 -4.93268486e+02\n  -2.85962376e+02 -5.42099620e+02]\n [-4.23945633e+02 -2.84957709e+02 -1.42597382e+02 -4.16203968e+01\n  -3.16687960e+02  0.00000000e+00 -6.24555241e+02            -inf\n             -inf -4.52711962e+02]\n [           -inf            -inf -4.44627542e+02  0.00000000e+00\n             -inf -4.96298954e+02            -inf            -inf\n             -inf            -inf]\n [-1.97615308e+02 -3.21188217e+01 -2.30629111e+02 -3.66239929e+01\n  -1.13242749e-14 -2.50425777e+02 -5.66047748e+02 -4.22446242e+02\n  -1.25339145e+02 -4.67346583e+02]\n [-2.00043603e+02 -5.47545529e+02 -2.01690912e+02  0.00000000e+00\n  -4.80272530e+02 -7.84844372e+01 -6.42897931e+02 -5.44146652e+02\n  -4.08158348e+02 -4.97918149e+02]\n [-2.87639975e+02 -3.71625580e+01  0.00000000e+00 -5.81750053e+01\n  -4.27106145e+02 -7.53086588e+01 -1.78145274e+02 -3.25503598e+02\n  -4.02870788e+02 -3.01298225e+02]\n [-3.46200165e+02 -3.63054029e+02 -2.77529533e+02  0.00000000e+00\n  -6.86110580e+02 -2.34542842e+02 -4.74886050e+02 -5.95675905e+02\n  -5.01979283e+02 -4.90916333e+02]\n [-4.98239771e+02 -3.64150960e+02 -1.31185214e+02 -1.24482040e-07\n  -5.24099992e+02 -1.58991045e+01 -5.56960310e+02            -inf\n  -3.00109050e+02 -5.90690684e+02]\n [           -inf            -inf -7.14136544e+02  0.00000000e+00\n             -inf -6.32185574e+02            -inf            -inf\n             -inf            -inf]\n [           -inf            -inf -1.82259893e+02  0.00000000e+00\n  -6.90741073e+02 -1.77007581e+02            -inf            -inf\n             -inf            -inf]\n [-1.01228787e+02 -3.92940835e+02 -2.01058774e+02 -2.12555823e+02\n  -1.93302072e+02  0.00000000e+00 -4.73329849e+02 -7.42648312e+02\n  -3.77032989e+02 -5.25089734e+02]\n [-2.93442270e+02 -1.03089996e+02 -1.22893312e+02 -1.87145682e+02\n             -inf  0.00000000e+00 -3.00061506e+02            -inf\n  -5.93719569e+02 -5.12575216e+02]\n [-3.82047887e+02 -4.68343392e+02 -1.59323857e+02  0.00000000e+00\n  -3.76958286e+02 -2.20753992e+02            -inf            -inf\n  -1.93897707e+02 -5.38466820e+02]\n [-1.81418293e+02 -3.37523827e+02 -2.15882823e+02  0.00000000e+00\n  -5.22756141e+02 -1.78845243e+02 -2.40389996e+02 -4.53459309e+02\n  -2.48274858e+02 -5.01352818e+02]\n [-4.45770341e+02 -2.74422431e+02 -2.23653646e+02  0.00000000e+00\n  -4.14792393e+02 -1.03702443e+02 -5.27038609e+02 -4.03568390e+02\n  -6.54368670e+02            -inf]\n [-5.43027627e+02 -4.52969997e+02 -3.55987487e+02  0.00000000e+00\n             -inf -1.88060468e+02 -7.16807567e+02 -6.18092469e+02\n  -4.70086362e+02            -inf]\n [           -inf -5.78048281e+02 -2.38160110e+02  0.00000000e+00\n  -2.56317172e+02 -1.30034616e+02 -6.20578805e+02            -inf\n  -3.96362027e+02            -inf]\n [-4.97553301e+02 -3.64147426e+02 -3.59973258e+02  0.00000000e+00\n  -6.65944229e+02 -2.62805744e+02 -6.07484813e+02 -7.05226834e+02\n  -4.80561950e+02            -inf]\n [-3.59711742e+02 -2.09452379e+02 -3.63940829e+02  0.00000000e+00\n  -4.07273568e+02 -2.86980561e+02 -3.81052002e+02 -7.02093315e+02\n  -2.26340985e+02 -7.18423386e+02]\n [-3.45578903e+02 -3.35526537e+02 -1.87205420e+02 -2.02458511e+01\n  -4.95606725e+02 -1.61190195e-09 -5.24549694e+02 -7.29309383e+02\n  -1.53995061e+02 -6.38839356e+02]\n [-5.66603528e+02 -3.08192431e+01 -3.80813262e+02 -4.13002965e-14\n  -2.33228649e+02 -5.01779789e+02            -inf -7.31598608e+02\n  -5.62913260e+02 -7.41801015e+02]\n [-3.35165871e+02 -4.07494206e+01 -1.21269001e+02 -7.92563629e-09\n  -1.91405360e+02 -1.86531632e+01 -3.24750642e+02 -2.61666325e+02\n  -5.66357846e+02 -4.01298928e+02]\n [-4.34396163e+02 -2.67258869e+02 -2.48467308e+02  0.00000000e+00\n  -3.63251281e+02 -3.67386727e+02 -6.73994713e+02            -inf\n  -3.49946699e+02            -inf]\n [-6.54248990e+02 -7.23749459e+02 -4.22379884e+02  0.00000000e+00\n             -inf -2.79635799e+02            -inf            -inf\n             -inf            -inf]\n [-5.28661947e+02 -2.84337500e+02 -1.19290802e-02 -2.53512301e+02\n  -2.03527194e+02 -4.43473475e+00 -5.09294308e+02 -6.82631966e+02\n  -6.70823254e+02 -4.65857242e+02]\n [-5.29130020e+02            -inf -2.78684194e+02  0.00000000e+00\n  -6.19560222e+02 -2.20936833e+02            -inf            -inf\n  -6.74770063e+02            -inf]\n [-7.02618489e+02            -inf -3.91143776e+02  0.00000000e+00\n  -6.61851518e+02 -1.61439424e+02            -inf -6.42893064e+02\n             -inf            -inf]\n [-2.79774951e+02 -4.33804917e+02 -1.78952189e+02 -1.22117328e+01\n             -inf -4.97179178e-06 -7.22354879e+02            -inf\n  -1.78909452e+02            -inf]\n [-5.44006845e+02 -1.59125150e+02  0.00000000e+00 -2.39165783e+02\n  -1.93614287e+02 -2.03487816e+02 -5.60623885e+02            -inf\n  -5.07293078e+02 -5.67858615e+02]\n [-3.37441317e+02 -4.32361639e+02 -3.31126975e+02  0.00000000e+00\n  -6.46277741e+02 -1.49680807e+02 -4.95187783e+02 -6.06561613e+02\n  -4.82013599e+02 -6.87800175e+02]\n [-4.86846822e+02 -3.19508417e+02 -3.78088112e+02 -1.42223479e+02\n  -5.94139195e+02  0.00000000e+00 -6.87928417e+02            -inf\n  -5.19308762e+02            -inf]])shape must be the same as MyTensor([[6.]\n [2.]\n [2.]\n [2.]\n [0.]\n [5.]\n [2.]\n [0.]\n [7.]\n [3.]\n [9.]\n [7.]\n [7.]\n [4.]\n [2.]\n [3.]\n [8.]\n [6.]\n [1.]\n [4.]\n [6.]\n [7.]\n [5.]\n [5.]\n [8.]\n [3.]\n [6.]\n [6.]\n [2.]\n [6.]\n [3.]\n [5.]\n [6.]\n [7.]\n [3.]\n [6.]\n [8.]\n [9.]\n [3.]\n [3.]\n [2.]\n [6.]\n [0.]\n [3.]\n [5.]\n [2.]\n [1.]\n [5.]\n [1.]\n [4.]\n [5.]\n [8.]\n [6.]\n [7.]\n [5.]\n [6.]\n [8.]\n [5.]\n [8.]\n [8.]\n [2.]\n [7.]\n [1.]\n [0.]])"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 859 ms (started: 2024-11-07 10:18:36 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from MyTorch import my_nn\n",
    "import MyTorch.loss_func\n",
    "import importlib\n",
    "importlib.reload(MyTorch)\n",
    "#构建model\n",
    "model=my_nn.Sequential(\n",
    "    my_nn.MyLinearLayer(input_size, hidden_size,initial_policy=\"He\"),\n",
    "    my_nn.ReLU(),\n",
    "    my_nn.MyLinearLayer(hidden_size, num_classes,initial_policy=\"He\"),\n",
    "    my_nn.Softmax(dim=1)\n",
    ")\n",
    "epochs=2\n",
    "# optimizer = MyTorch.optim.SGD(model.parameters, lr=lr, momentum=momentum)\n",
    "optimizer=MyTorch.optim.Adam(model.parameters,lr=0.01)\n",
    "criterion = MyTorch.loss_func.NLLLoss()\n",
    "for epoch in range(epochs):\n",
    "    for images, labels in train_dataloader:\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.data.astype(float):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytor-basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
