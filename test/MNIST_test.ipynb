{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验计划\n",
    "\n",
    "模型架构mlp+softmax多分类\n",
    "\n",
    "1.实现pytorch版,并且稍微调参\n",
    "\n",
    "2.复刻myTorch版\n",
    "\n",
    "3.基于myTorch做消融实验(优化器，初始化策略)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 2.03 ms (started: 2024-11-04 15:43:15 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 用于记录每个单元格的运行时间\n",
    "\n",
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/myTorch\n",
      "time: 2.25 ms (started: 2024-11-04 15:43:15 +08:00)\n"
     ]
    }
   ],
   "source": [
    "#把项目目录添加至环境变量\n",
    "import os\n",
    "import sys\n",
    "# 获取当前工作目录\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# 获取上级目录\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "print(parent_dir)\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:torch.Size([60000, 28, 28])\n",
      "mean:33.31842041015625\n",
      "train_data: 54000\n",
      "val_data: 6000\n",
      "device:cuda\n",
      "time: 112 ms (started: 2024-11-04 15:56:43 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 基于pytorch导入数据\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "import MyTorch.Dataloader\n",
    "data_dir = \"../../dataset\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 转换为Tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)),  # 归一化，均值为0.5，标准差为0.5\n",
    "])\n",
    "# MNIST dataset\n",
    "train_data_full = datasets.MNIST(data_dir, train=True, download=True, transform=data_transforms)\n",
    "test_data = datasets.MNIST(data_dir, train=False, download=True, transform=data_transforms)\n",
    "\n",
    "print(f\"shape:{train_data_full.data.shape}\")\n",
    "print(f\"mean:{train_data_full.data.float().mean()}\")#pytorch dataset的transform只会在取数据进入model时调用，故此时print仍然是原始数据\n",
    "\n",
    "val_size = int(0.1 * len(train_data_full))\n",
    "train_data, val_data = random_split(train_data_full, [len(train_data_full) - val_size, val_size])\n",
    "print(\"train_data:\", len(train_data))\n",
    "print(\"val_data:\", len(val_data))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device:{device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 338 μs (started: 2024-11-04 15:43:15 +08:00)\n"
     ]
    }
   ],
   "source": [
    "#定义固定参数\n",
    "input_size = 28 * 28\n",
    "num_classes = 10\n",
    "#定义超参\n",
    "batch_size = 64\n",
    "hidden_size = 128\n",
    "lr=0.1\n",
    "momentum = 0.9\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.92 ms (started: 2024-11-04 15:43:15 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 构建model\n",
    "from torch import nn\n",
    "model=torch.nn.Sequential(nn.Linear(input_size, hidden_size),nn.ReLU(),nn.Linear(hidden_size, num_classes),nn.Softmax(dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 957 μs (started: 2024-11-04 15:43:15 +08:00)\n"
     ]
    }
   ],
   "source": [
    "def val_eval(model,val_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.view(-1, 28 * 28)\n",
    "            images,labels=images.to(device),labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += len(labels)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc=correct/total\n",
    "    print(f\"acc:{acc}\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 687 μs (started: 2024-11-04 15:43:15 +08:00)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import optuna\n",
    "except ModuleNotFoundError:\n",
    "    !pip install optuna\n",
    "    import optuna\n",
    "\n",
    "try:\n",
    "    import tqdm\n",
    "except ModuleNotFoundError:\n",
    "    !pip install tqdm\n",
    "    import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.36 ms (started: 2024-11-04 15:43:15 +08:00)\n"
     ]
    }
   ],
   "source": [
    "def obj(trails):\n",
    "    kwargs = {\n",
    "        \"hidden_size\": trails.suggest_int(\"hidden_size\", 32, 128),\n",
    "        \"batch_size\": trails.suggest_int(\"batch_size\", 64, 64),\n",
    "        \"lr\": trails.suggest_float(\"lr\", 0.001, 0.1),\n",
    "        \"momentum\": trails.suggest_float(\"momentum\", 0.5, 0.9),\n",
    "        epochs: trails.suggest_int(\"epochs\", 2,10 ),\n",
    "    }\n",
    "    model=torch.nn.Sequential(nn.Linear(input_size, kwargs[\"hidden_size\"]),nn.ReLU(),nn.Linear(kwargs[\"hidden_size\"], num_classes),nn.Softmax(dim=1)).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=kwargs[\"lr\"],weight_decay=0.01,momentum=kwargs[\"momentum\"])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_loader =torch.utils.data.DataLoader(train_data, batch_size=kwargs[\"batch_size\"], shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=kwargs[\"batch_size\"], shuffle=False)\n",
    "    for epoch in range(kwargs[epochs]):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images=images.view(-1,28*28)\n",
    "            images,labels=images.to(device),labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 256 == 0:\n",
    "                print('Epcho [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch, kwargs[epochs], i + 1, len(train_loader), loss.item()))\n",
    "    return val_eval(model,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:43:15,384] A new study created in memory with name: no-name-6df1797f-f235-44b5-b9eb-3ed3af85f4c4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epcho [0/5], Step [256/844], Loss: 1.8234\n",
      "Epcho [0/5], Step [512/844], Loss: 1.6936\n",
      "Epcho [0/5], Step [768/844], Loss: 1.7346\n",
      "Epcho [1/5], Step [256/844], Loss: 1.6231\n",
      "Epcho [1/5], Step [512/844], Loss: 1.5874\n",
      "Epcho [1/5], Step [768/844], Loss: 1.6841\n",
      "Epcho [2/5], Step [256/844], Loss: 1.6381\n",
      "Epcho [2/5], Step [512/844], Loss: 1.6210\n",
      "Epcho [2/5], Step [768/844], Loss: 1.5802\n",
      "Epcho [3/5], Step [256/844], Loss: 1.5984\n",
      "Epcho [3/5], Step [512/844], Loss: 1.6160\n",
      "Epcho [3/5], Step [768/844], Loss: 1.6319\n",
      "Epcho [4/5], Step [256/844], Loss: 1.5426\n",
      "Epcho [4/5], Step [512/844], Loss: 1.5979\n",
      "Epcho [4/5], Step [768/844], Loss: 1.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:43:50,001] Trial 0 finished with value: 0.905 and parameters: {'hidden_size': 84, 'batch_size': 64, 'lr': 0.048158069573203, 'momentum': 0.5800218672518666, 'epochs': 5}. Best is trial 0 with value: 0.905.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.905\n",
      "Epcho [0/9], Step [256/844], Loss: 1.8083\n",
      "Epcho [0/9], Step [512/844], Loss: 1.7627\n",
      "Epcho [0/9], Step [768/844], Loss: 1.6454\n",
      "Epcho [1/9], Step [256/844], Loss: 1.8191\n",
      "Epcho [1/9], Step [512/844], Loss: 1.7014\n",
      "Epcho [1/9], Step [768/844], Loss: 1.6850\n",
      "Epcho [2/9], Step [256/844], Loss: 1.5953\n",
      "Epcho [2/9], Step [512/844], Loss: 1.6513\n",
      "Epcho [2/9], Step [768/844], Loss: 1.6064\n",
      "Epcho [3/9], Step [256/844], Loss: 1.6671\n",
      "Epcho [3/9], Step [512/844], Loss: 1.5993\n",
      "Epcho [3/9], Step [768/844], Loss: 1.6409\n",
      "Epcho [4/9], Step [256/844], Loss: 1.6378\n",
      "Epcho [4/9], Step [512/844], Loss: 1.5856\n",
      "Epcho [4/9], Step [768/844], Loss: 1.5886\n",
      "Epcho [5/9], Step [256/844], Loss: 1.5755\n",
      "Epcho [5/9], Step [512/844], Loss: 1.6198\n",
      "Epcho [5/9], Step [768/844], Loss: 1.6121\n",
      "Epcho [6/9], Step [256/844], Loss: 1.5892\n",
      "Epcho [6/9], Step [512/844], Loss: 1.6596\n",
      "Epcho [6/9], Step [768/844], Loss: 1.5978\n",
      "Epcho [7/9], Step [256/844], Loss: 1.6144\n",
      "Epcho [7/9], Step [512/844], Loss: 1.6433\n",
      "Epcho [7/9], Step [768/844], Loss: 1.6277\n",
      "Epcho [8/9], Step [256/844], Loss: 1.6680\n",
      "Epcho [8/9], Step [512/844], Loss: 1.5925\n",
      "Epcho [8/9], Step [768/844], Loss: 1.5885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:44:51,495] Trial 1 finished with value: 0.907 and parameters: {'hidden_size': 117, 'batch_size': 64, 'lr': 0.026192165546679236, 'momentum': 0.622243329796311, 'epochs': 9}. Best is trial 1 with value: 0.907.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.907\n",
      "Epcho [0/6], Step [256/844], Loss: 1.7430\n",
      "Epcho [0/6], Step [512/844], Loss: 1.6521\n",
      "Epcho [0/6], Step [768/844], Loss: 1.6996\n",
      "Epcho [1/6], Step [256/844], Loss: 1.6377\n",
      "Epcho [1/6], Step [512/844], Loss: 1.6865\n",
      "Epcho [1/6], Step [768/844], Loss: 1.6739\n",
      "Epcho [2/6], Step [256/844], Loss: 1.6201\n",
      "Epcho [2/6], Step [512/844], Loss: 1.6402\n",
      "Epcho [2/6], Step [768/844], Loss: 1.6341\n",
      "Epcho [3/6], Step [256/844], Loss: 1.6237\n",
      "Epcho [3/6], Step [512/844], Loss: 1.5964\n",
      "Epcho [3/6], Step [768/844], Loss: 1.6364\n",
      "Epcho [4/6], Step [256/844], Loss: 1.5518\n",
      "Epcho [4/6], Step [512/844], Loss: 1.5611\n",
      "Epcho [4/6], Step [768/844], Loss: 1.5656\n",
      "Epcho [5/6], Step [256/844], Loss: 1.6669\n",
      "Epcho [5/6], Step [512/844], Loss: 1.6378\n",
      "Epcho [5/6], Step [768/844], Loss: 1.6819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:45:31,958] Trial 2 finished with value: 0.9071666666666667 and parameters: {'hidden_size': 112, 'batch_size': 64, 'lr': 0.08386399032153453, 'momentum': 0.5947152101611084, 'epochs': 6}. Best is trial 2 with value: 0.9071666666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.9071666666666667\n",
      "Epcho [0/7], Step [256/844], Loss: 1.8138\n",
      "Epcho [0/7], Step [512/844], Loss: 1.6473\n",
      "Epcho [0/7], Step [768/844], Loss: 1.6242\n",
      "Epcho [1/7], Step [256/844], Loss: 1.6165\n",
      "Epcho [1/7], Step [512/844], Loss: 1.5554\n",
      "Epcho [1/7], Step [768/844], Loss: 1.6466\n",
      "Epcho [2/7], Step [256/844], Loss: 1.6055\n",
      "Epcho [2/7], Step [512/844], Loss: 1.5978\n",
      "Epcho [2/7], Step [768/844], Loss: 1.6162\n",
      "Epcho [3/7], Step [256/844], Loss: 1.5821\n",
      "Epcho [3/7], Step [512/844], Loss: 1.5994\n",
      "Epcho [3/7], Step [768/844], Loss: 1.6678\n",
      "Epcho [4/7], Step [256/844], Loss: 1.6048\n",
      "Epcho [4/7], Step [512/844], Loss: 1.5880\n",
      "Epcho [4/7], Step [768/844], Loss: 1.6159\n",
      "Epcho [5/7], Step [256/844], Loss: 1.6026\n",
      "Epcho [5/7], Step [512/844], Loss: 1.5967\n",
      "Epcho [5/7], Step [768/844], Loss: 1.5537\n",
      "Epcho [6/7], Step [256/844], Loss: 1.5460\n",
      "Epcho [6/7], Step [512/844], Loss: 1.5703\n",
      "Epcho [6/7], Step [768/844], Loss: 1.5782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:46:19,115] Trial 3 finished with value: 0.9118333333333334 and parameters: {'hidden_size': 114, 'batch_size': 64, 'lr': 0.03465737987331803, 'momentum': 0.8057131288832868, 'epochs': 7}. Best is trial 3 with value: 0.9118333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.9118333333333334\n",
      "Epcho [0/3], Step [256/844], Loss: 1.6271\n",
      "Epcho [0/3], Step [512/844], Loss: 1.6747\n",
      "Epcho [0/3], Step [768/844], Loss: 1.6305\n",
      "Epcho [1/3], Step [256/844], Loss: 1.5538\n",
      "Epcho [1/3], Step [512/844], Loss: 1.6638\n",
      "Epcho [1/3], Step [768/844], Loss: 1.5670\n",
      "Epcho [2/3], Step [256/844], Loss: 1.6190\n",
      "Epcho [2/3], Step [512/844], Loss: 1.5728\n",
      "Epcho [2/3], Step [768/844], Loss: 1.5590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:46:39,636] Trial 4 finished with value: 0.8946666666666667 and parameters: {'hidden_size': 86, 'batch_size': 64, 'lr': 0.08125572847743215, 'momentum': 0.6826258064144499, 'epochs': 3}. Best is trial 3 with value: 0.9118333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.8946666666666667\n",
      "Epcho [0/7], Step [256/844], Loss: 1.7782\n",
      "Epcho [0/7], Step [512/844], Loss: 1.7338\n",
      "Epcho [0/7], Step [768/844], Loss: 1.8554\n",
      "Epcho [1/7], Step [256/844], Loss: 1.7009\n",
      "Epcho [1/7], Step [512/844], Loss: 1.6037\n",
      "Epcho [1/7], Step [768/844], Loss: 1.5977\n",
      "Epcho [2/7], Step [256/844], Loss: 1.6872\n",
      "Epcho [2/7], Step [512/844], Loss: 1.6144\n",
      "Epcho [2/7], Step [768/844], Loss: 1.5968\n",
      "Epcho [3/7], Step [256/844], Loss: 1.6242\n",
      "Epcho [3/7], Step [512/844], Loss: 1.6043\n",
      "Epcho [3/7], Step [768/844], Loss: 1.5923\n",
      "Epcho [4/7], Step [256/844], Loss: 1.6158\n",
      "Epcho [4/7], Step [512/844], Loss: 1.6641\n",
      "Epcho [4/7], Step [768/844], Loss: 1.6200\n",
      "Epcho [5/7], Step [256/844], Loss: 1.6086\n",
      "Epcho [5/7], Step [512/844], Loss: 1.5659\n",
      "Epcho [5/7], Step [768/844], Loss: 1.6013\n",
      "Epcho [6/7], Step [256/844], Loss: 1.6493\n",
      "Epcho [6/7], Step [512/844], Loss: 1.6273\n",
      "Epcho [6/7], Step [768/844], Loss: 1.6182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:47:26,797] Trial 5 finished with value: 0.9053333333333333 and parameters: {'hidden_size': 89, 'batch_size': 64, 'lr': 0.028592217180912864, 'momentum': 0.7727646122572475, 'epochs': 7}. Best is trial 3 with value: 0.9118333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.9053333333333333\n",
      "Epcho [0/2], Step [256/844], Loss: 1.6703\n",
      "Epcho [0/2], Step [512/844], Loss: 1.7070\n",
      "Epcho [0/2], Step [768/844], Loss: 1.6383\n",
      "Epcho [1/2], Step [256/844], Loss: 1.6832\n",
      "Epcho [1/2], Step [512/844], Loss: 1.6445\n",
      "Epcho [1/2], Step [768/844], Loss: 1.5914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:47:40,735] Trial 6 finished with value: 0.8903333333333333 and parameters: {'hidden_size': 115, 'batch_size': 64, 'lr': 0.045840187004281344, 'momentum': 0.6193892476972579, 'epochs': 2}. Best is trial 3 with value: 0.9118333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.8903333333333333\n",
      "Epcho [0/9], Step [256/844], Loss: 2.0659\n",
      "Epcho [0/9], Step [512/844], Loss: 1.9434\n",
      "Epcho [0/9], Step [768/844], Loss: 1.8979\n",
      "Epcho [1/9], Step [256/844], Loss: 1.8272\n",
      "Epcho [1/9], Step [512/844], Loss: 1.6898\n",
      "Epcho [1/9], Step [768/844], Loss: 1.6775\n",
      "Epcho [2/9], Step [256/844], Loss: 1.6033\n",
      "Epcho [2/9], Step [512/844], Loss: 1.6753\n",
      "Epcho [2/9], Step [768/844], Loss: 1.6305\n",
      "Epcho [3/9], Step [256/844], Loss: 1.6494\n",
      "Epcho [3/9], Step [512/844], Loss: 1.6158\n",
      "Epcho [3/9], Step [768/844], Loss: 1.6142\n",
      "Epcho [4/9], Step [256/844], Loss: 1.6403\n",
      "Epcho [4/9], Step [512/844], Loss: 1.6061\n",
      "Epcho [4/9], Step [768/844], Loss: 1.6253\n",
      "Epcho [5/9], Step [256/844], Loss: 1.5953\n",
      "Epcho [5/9], Step [512/844], Loss: 1.5573\n",
      "Epcho [5/9], Step [768/844], Loss: 1.6189\n",
      "Epcho [6/9], Step [256/844], Loss: 1.5964\n",
      "Epcho [6/9], Step [512/844], Loss: 1.5744\n",
      "Epcho [6/9], Step [768/844], Loss: 1.5972\n",
      "Epcho [7/9], Step [256/844], Loss: 1.6726\n",
      "Epcho [7/9], Step [512/844], Loss: 1.6114\n",
      "Epcho [7/9], Step [768/844], Loss: 1.5758\n",
      "Epcho [8/9], Step [256/844], Loss: 1.6050\n",
      "Epcho [8/9], Step [512/844], Loss: 1.5932\n",
      "Epcho [8/9], Step [768/844], Loss: 1.5937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:48:40,855] Trial 7 finished with value: 0.9021666666666667 and parameters: {'hidden_size': 114, 'batch_size': 64, 'lr': 0.013845741240680661, 'momentum': 0.5308481853025109, 'epochs': 9}. Best is trial 3 with value: 0.9118333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.9021666666666667\n",
      "Epcho [0/2], Step [256/844], Loss: 1.7106\n",
      "Epcho [0/2], Step [512/844], Loss: 1.8768\n",
      "Epcho [0/2], Step [768/844], Loss: 1.6719\n",
      "Epcho [1/2], Step [256/844], Loss: 1.6384\n",
      "Epcho [1/2], Step [512/844], Loss: 1.5942\n",
      "Epcho [1/2], Step [768/844], Loss: 1.5762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:48:54,869] Trial 8 finished with value: 0.8975 and parameters: {'hidden_size': 63, 'batch_size': 64, 'lr': 0.02604661414070332, 'momentum': 0.8097798962822866, 'epochs': 2}. Best is trial 3 with value: 0.9118333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.8975\n",
      "Epcho [0/7], Step [256/844], Loss: 1.7798\n",
      "Epcho [0/7], Step [512/844], Loss: 1.6369\n",
      "Epcho [0/7], Step [768/844], Loss: 1.5939\n",
      "Epcho [1/7], Step [256/844], Loss: 1.6848\n",
      "Epcho [1/7], Step [512/844], Loss: 1.6126\n",
      "Epcho [1/7], Step [768/844], Loss: 1.6369\n",
      "Epcho [2/7], Step [256/844], Loss: 1.6470\n",
      "Epcho [2/7], Step [512/844], Loss: 1.6486\n",
      "Epcho [2/7], Step [768/844], Loss: 1.5892\n",
      "Epcho [3/7], Step [256/844], Loss: 1.5693\n",
      "Epcho [3/7], Step [512/844], Loss: 1.6175\n",
      "Epcho [3/7], Step [768/844], Loss: 1.5964\n",
      "Epcho [4/7], Step [256/844], Loss: 1.5593\n",
      "Epcho [4/7], Step [512/844], Loss: 1.6193\n",
      "Epcho [4/7], Step [768/844], Loss: 1.5616\n",
      "Epcho [5/7], Step [256/844], Loss: 1.5928\n",
      "Epcho [5/7], Step [512/844], Loss: 1.6234\n",
      "Epcho [5/7], Step [768/844], Loss: 1.6238\n",
      "Epcho [6/7], Step [256/844], Loss: 1.5769\n",
      "Epcho [6/7], Step [512/844], Loss: 1.6161\n",
      "Epcho [6/7], Step [768/844], Loss: 1.5871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-04 15:49:42,254] Trial 9 finished with value: 0.9058333333333334 and parameters: {'hidden_size': 49, 'batch_size': 64, 'lr': 0.09058703178482988, 'momentum': 0.631339603916554, 'epochs': 7}. Best is trial 3 with value: 0.9118333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.9058333333333334\n",
      "time: 6min 26s (started: 2024-11-04 15:43:15 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class TqdmCallback(object):\n",
    "    def __init__(self, n_trials):\n",
    "        self.n_trials = n_trials\n",
    "        self.pbar = tqdm(total=n_trials)\n",
    "\n",
    "    def __call__(self, study, trial):\n",
    "        self.pbar.update(1)\n",
    "\n",
    "n_trials = 10\n",
    "tqdm_callback = TqdmCallback(n_trials)\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(obj, n_trials=n_trials, callbacks=[tqdm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.24 ms (started: 2024-11-04 15:52:30 +08:00)\n"
     ]
    }
   ],
   "source": [
    "#固定掉超参数\n",
    "lr= 0.09058703178482988\n",
    "hidden_size=50\n",
    "momentum=0.631339603916554\n",
    "epochs=10 #几个不同epoch差别不太大，多训两轮是不会导致性能明显下降的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.5631\n",
      "Epoch [2/10], Loss: 1.5118\n",
      "Epoch [3/10], Loss: 1.5162\n",
      "Epoch [4/10], Loss: 1.5068\n",
      "Epoch [5/10], Loss: 1.5694\n",
      "Epoch [6/10], Loss: 1.5101\n",
      "Epoch [7/10], Loss: 1.5532\n",
      "Epoch [8/10], Loss: 1.5066\n",
      "Epoch [9/10], Loss: 1.5489\n",
      "Epoch [10/10], Loss: 1.4948\n",
      "time: 1min 15s (started: 2024-11-04 16:04:49 +08:00)\n"
     ]
    }
   ],
   "source": [
    "#使用完整训练集训练并测试pytorch版\n",
    "train_loader_full = torch.utils.data.DataLoader(train_data_full, batch_size=batch_size, shuffle=True)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, num_classes),\n",
    "    nn.Softmax(dim=1)\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for images, labels in train_loader_full:\n",
    "        images = images.view(-1, 28 * 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.9546\n",
      "final acc:0.9546\n",
      "time: 1.13 s (started: 2024-11-04 16:06:07 +08:00)\n"
     ]
    }
   ],
   "source": [
    "#使用测试集测试\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "acc=val_eval(model,test_loader)\n",
    "print(f\"final acc:{acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 71.6 ms (started: 2024-11-04 16:28:01 +08:00)\n"
     ]
    }
   ],
   "source": [
    "#基于myTorch进行构建\n",
    "#基于myTorch的dataset导入数据\n",
    "import MyTorch.Dataloader\n",
    "import numpy as np\n",
    "#把dataset转为numpy的形式\n",
    "class trans2MyTensor:\n",
    "    def __call__(self, img):\n",
    "        np_img=np.array(img)\n",
    "        np_img_flat=np_img.flatten()\n",
    "        #归一化到0 1\n",
    "        min_val = np.min(np_img_flat)\n",
    "        max_val = np.max(np_img_flat)\n",
    "        np_img_flat = (np_img_flat - min_val) / (max_val - min_val)\n",
    "        result=MyTorch.myTensor(np_img_flat)\n",
    "        return result\n",
    "myTensor_transforms = transforms.Compose([\n",
    "    trans2MyTensor()\n",
    "])\n",
    "train_data_full = datasets.MNIST(data_dir, train=True, download=True, transform=myTensor_transforms)\n",
    "test_data = datasets.MNIST(data_dir, train=False, download=True, transform=myTensor_transforms)\n",
    "\n",
    "train_dataloader = MyTorch.Dataloader.DataLoader(train_data_full, batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = MyTorch.Dataloader.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m MyTorch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters, lr\u001b[38;5;241m=\u001b[39mlr, momentum\u001b[38;5;241m=\u001b[39mmomentum)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m     16\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     17\u001b[0m         loss \u001b[38;5;241m=\u001b[39m MyTorch\u001b[38;5;241m.\u001b[39mloss_func\u001b[38;5;241m.\u001b[39mCrossEntropyLoss\u001b[38;5;241m.\u001b[39mforward(outputs, labels)\n",
      "File \u001b[0;32m~/autodl-tmp/myTorch/MyTorch/Dataloader.py:106\u001b[0m, in \u001b[0;36mIterater.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    105\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterater)\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader\u001b[38;5;241m.\u001b[39mdataset[idx]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torchvision/datasets/mnist.py:139\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, Any]:\n\u001b[1;32m    132\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m        index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m        tuple: (image, target) where target is index of the target class.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index])\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 65.6 ms (started: 2024-11-04 16:45:37 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from MyTorch import my_nn\n",
    "import MyTorch.loss_func\n",
    "import importlib\n",
    "importlib.reload(MyTorch)\n",
    "#构建model\n",
    "model=my_nn.Sequential(\n",
    "    my_nn.MyLinearLayer(input_size, hidden_size),\n",
    "    my_nn.ReLU(),\n",
    "    my_nn.MyLinearLayer(hidden_size, num_classes),\n",
    "    my_nn.Softmax(dim=1)\n",
    ")\n",
    "epochs=1\n",
    "optimizer = MyTorch.optim.SGD(model.parameters, lr=lr, momentum=momentum)\n",
    "for epoch in range(epochs):\n",
    "    for images, labels in train_dataloader:\n",
    "        outputs = model(images)\n",
    "        loss = MyTorch.loss_func.CrossEntropyLoss.forward(outputs, labels)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
