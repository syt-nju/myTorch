{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "# 获取当前工作目录\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# 获取上级目录\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  4.  6.]\n",
      " [ 8. 10. 12.]]\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from MyTorch_v2.myTensor import MyTensor,Add\n",
    "import numpy as np\n",
    "#构造两个2*3的张量\n",
    "a = MyTensor(np.array([[1,2,3],[4,5,6]]),requires_grad=True)\n",
    "b= MyTensor(np.array([[1,2,3],[4,5,6]]))\n",
    "c=Add.forward(a,b)\n",
    "print(c.data)\n",
    "c.backward()\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "[[-1. -1. -1.]\n",
      " [-1. -1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "#test for sub\n",
    "from MyTorch_v2.myTensor import Sub\n",
    "a = MyTensor(np.array([[1,2,3],[4,5,6]]),requires_grad=True)\n",
    "b= MyTensor(np.array([[1,2,3],[4,5,6]]),requires_grad=True)\n",
    "c=Sub.forward(a,b)\n",
    "print(c.data)\n",
    "c.backward()\n",
    "print(a.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  4.  9.]\n",
      " [ 4. 10. 18.]]\n",
      "[[1. 2. 3.]\n",
      " [1. 2. 3.]]\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "#test for mul\n",
    "from MyTorch_v2.myTensor import Mul\n",
    "a = MyTensor(np.array([[1,2,3],[4,5,6]]),requires_grad=True)\n",
    "b= MyTensor(np.array([[1,2,3],[1,2,3]]),requires_grad=True)\n",
    "c=Mul.forward(a,b)\n",
    "print(c.data)\n",
    "c.backward()\n",
    "print(a.grad)\n",
    "print(b.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 28.]]\n",
      "[[ 3.  7. 11.]]\n",
      "[[1. 1.]\n",
      " [2. 2.]\n",
      " [3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "#test for matmul\n",
    "from MyTorch_v2.myTensor import MatMul\n",
    "# a=MyTensor(np.array([[1,2,3],[4,5,6]]),requires_grad=True)\n",
    "# b=MyTensor(np.array([[1,2],[3,4],[5,6]]),requires_grad=True)\n",
    "# c=MatMul.forward(a,b)\n",
    "# # print(c.data)\n",
    "# c.backward()\n",
    "# # print(a.grad)\n",
    "# # print(b.grad)\n",
    "\n",
    "#test for one_dim_matmul\n",
    "a=MyTensor(np.array([[1,2,3]]),requires_grad=True)\n",
    "b=MyTensor(np.array([[1,2],[3,4],[5,6]]),requires_grad=True)\n",
    "c=MatMul.forward(a,b)\n",
    "print(c.data)\n",
    "c.backward()\n",
    "print(a.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "[[1.         0.5        0.33333333]\n",
      " [0.25       0.2        0.16666667]]\n",
      "[[-1.         -0.5        -0.33333333]\n",
      " [-0.25       -0.2        -0.16666667]]\n"
     ]
    }
   ],
   "source": [
    "#test for div\n",
    "from MyTorch_v2.myTensor import Div\n",
    "a=MyTensor(np.array([[1,2,3],[4,5,6]]),requires_grad=True)\n",
    "b=MyTensor(np.array([[1,2,3],[4,5,6]]),requires_grad=True)\n",
    "c=Div.forward(a,b)\n",
    "print(c.data)\n",
    "c.backward()\n",
    "print(a.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 6.]\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#test for max\n",
    "from MyTorch_v2.myTensor import Max\n",
    "a=MyTensor(np.array([[1,2,3],[4,5,6]]),requires_grad=True)\n",
    "c=Max.forward(a,axis=1,keepdims=False)\n",
    "print(c.data)\n",
    "c.backward()\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.71828183   7.3890561   20.08553692]\n",
      " [ 54.59815003 148.4131591  403.42879349]]\n",
      "[[  2.71828183   7.3890561   20.08553692]\n",
      " [ 54.59815003 148.4131591  403.42879349]]\n",
      "[[  2.71828183   7.3890561   20.08553692]\n",
      " [ 54.59815003 148.4131591  403.42879349]]\n",
      "[[1.36787944 1.13533528 1.04978707]\n",
      " [1.01831564 1.00673795 1.00247875]]\n"
     ]
    }
   ],
   "source": [
    "#test for exp log\n",
    "from MyTorch_v2.myTensor import Exp,Log\n",
    "a=MyTensor(np.array([[1,2,3],[4,5,6]]),requires_grad=True)\n",
    "c=Exp.forward(a)\n",
    "print(c.data)\n",
    "c.backward()\n",
    "print(a.grad)\n",
    "d=Log.forward(c)\n",
    "print(c.data)\n",
    "d.backward()\n",
    "print(c.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6. 15.]\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#test for sumunary\n",
    "from MyTorch_v2.myTensor import SumUnary\n",
    "a=MyTensor(np.array([[1,2,3],[4,5,6]]),requires_grad=True)\n",
    "c=SumUnary.forward(a,axis=1,keepdims=False)\n",
    "print(c.data)\n",
    "c.backward()\n",
    "print(a.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytor-basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
