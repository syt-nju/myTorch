{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#测试Exp算子\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mMyTensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mMyTorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m myAssert\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "#测试Exp算子\n",
    "from MyTensor import *\n",
    "import numpy as np\n",
    "from MyTorch.utils.utils import myAssert\n",
    "\n",
    "for i in range(1000):\n",
    "    a=MyTensor.MyTensor(np.random.rand(2,3),requires_grad=True)\n",
    "    Exp=MyTensor.Exp()\n",
    "    b = Exp.forward(a)\n",
    "    b.backward()\n",
    "    myAssert((b.data== a.grad).all(), \"something wrong with Exp\",b.data,a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#简单测试Log\n",
    "a=MyTensor.MyTensor(np.array([[1,2,3],[4,5,6]]),requires_grad=True)\n",
    "Log=MyTensor.Log()\n",
    "b = Log.forward(a)\n",
    "b.backward()\n",
    "print(b.data)\n",
    "print(a.grad)\n",
    "print(1/a.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#测试Log算子\n",
    "import MyTensor\n",
    "import numpy as np\n",
    "from utils.utils import myAssert\n",
    "for i in range(1000):\n",
    "    a=MyTensor.MyTensor(np.random.rand(1,10),requires_grad=True)\n",
    "    Log=MyTensor.Log()\n",
    "    b = Log.forward(a)\n",
    "    b.backward()\n",
    "    myAssert((a.grad==1/a.data).all(), \"something wrong with Log\",b.data,a.grad,a.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试SumUnary算子\n",
    "from MyTensor import MyTensor,SumUnary\n",
    "import numpy as np\n",
    "a=MyTensor(np.random.rand(2,3),requires_grad=True)\n",
    "Sum=SumUnary(axis=0)\n",
    "b = Sum.forward(a)\n",
    "b.backward()\n",
    "print(b.data)\n",
    "print(a.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试div算子\n",
    "from MyTensor import MyTensor,Div\n",
    "import numpy as np\n",
    "a=MyTensor(np.array([[1,2,3],[4,5,6]]),requires_grad=True)\n",
    "b=MyTensor(np.array([[2,2,2],[2,2,2]]),requires_grad=True)\n",
    "Div=Div()\n",
    "c = Div.forward(a,b)\n",
    "c.backward()\n",
    "print(c.data)\n",
    "print(a.grad)\n",
    "print(b.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试softmax层\n",
    "from my_nn import Softmax\n",
    "from MyTensor import MyTensor\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils.utils import myAssert    \n",
    "for i in range(1000):\n",
    "    for dim in range(2):\n",
    "        a_np=np.random.rand(2,3)\n",
    "        a=MyTensor(a_np,requires_grad=True)\n",
    "        a_torch=torch.tensor(a_np,requires_grad=True)\n",
    "        softmax=Softmax(dim=dim)\n",
    "        b=softmax.forward(a)\n",
    "        b_torch=torch.nn.functional.softmax(a_torch,dim=dim)\n",
    "        b.backward()\n",
    "        b_torch.backward(torch.ones_like(b_torch))\n",
    "        assert np.allclose(b.data,b_torch.detach().numpy())\n",
    "        myAssert(np.allclose(a.grad,a_torch.grad.detach().numpy()),\"something wrong with softmax\",a.grad,a_torch.grad.detach().numpy())\n",
    "print(\"softmax test passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 2. 3.]\n",
      " [4. 0. 6.]]\n",
      "[[0. 1. 1.]\n",
      " [1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#relu测试\n",
    "from my_nn import ReLU\n",
    "from MyTensor import MyTensor\n",
    "import numpy as np\n",
    "\n",
    "a=MyTensor(np.array([[-1,2,3],[4,-5,6]]),requires_grad=True)\n",
    "relu=ReLU()\n",
    "b=relu.forward(a)\n",
    "b.backward()\n",
    "print(b.data)\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "None\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "Model structure:\n",
      "   Sequential(\n",
      "        MLP(3,4,2)\n",
      "        ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from my_nn import ReLU,MLP,Sequential\n",
    "from MyTensor import MyTensor\n",
    "import numpy as np\n",
    "\n",
    "a=MyTensor(np.array([[-1,2,3],[4,-5,6]]),requires_grad=False)\n",
    "model=Sequential(MLP(3,4,2,initial_policy='zeros'),ReLU())\n",
    "b=model.forward(a)\n",
    "b.backward()\n",
    "print(b.data)\n",
    "print(a.grad)\n",
    "print(model.layers[0].parameters[0].grad)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytor-basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
